{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False CPU\n",
      "Original sizes: 257478 39642 99069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 257478/257478 [00:01<00:00, 192815.48 examples/s]\n",
      "Filter: 100%|██████████| 39642/39642 [00:00<00:00, 171263.97 examples/s]\n",
      "Filter: 100%|██████████| 99069/99069 [00:00<00:00, 180996.77 examples/s]\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_17040\\2574649099.py:55: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(cap, len(x)), random_state=seed))\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_17040\\2574649099.py:55: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(cap, len(x)), random_state=seed))\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_17040\\2574649099.py:55: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(cap, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsized sizes: 15768 3881 7820\n",
      "Labels contiguous? False (#classes = 20 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15768/15768 [00:00<00:00, 18400.09 examples/s]\n",
      "Map: 100%|██████████| 3881/3881 [00:00<00:00, 18862.87 examples/s]\n",
      "Map: 100%|██████████| 7820/7820 [00:00<00:00, 19117.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15768/15768 [00:01<00:00, 9499.84 examples/s] \n",
      "Map: 100%|██████████| 3881/3881 [00:00<00:00, 10553.34 examples/s]\n",
      "Map: 100%|██████████| 7820/7820 [00:00<00:00, 10535.09 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_17040\\2574649099.py:149: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 20:43, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEV (overall) ===\n",
      "Accuracy : 0.4728\n",
      "Macro-F1 : 0.4005\n",
      "\n",
      "=== DEV per-gender ===\n",
      "                     n       acc  macro_f1\n",
      "male       1929.000000  0.469673  0.382835\n",
      "female     1952.000000  0.475922  0.415788\n",
      "Δacc         -0.006249 -0.006249 -0.006249\n",
      "Δmacro_f1    -0.032953 -0.032953 -0.032953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4293604\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST (overall) ===\n",
      "Accuracy : 0.4772\n",
      "Macro-F1 : 0.4044\n",
      "\n",
      "=== TEST per-gender ===\n",
      "                     n       acc  macro_f1\n",
      "male       3871.000000  0.481788  0.396591\n",
      "female     3949.000000  0.472778  0.407671\n",
      "Δacc          0.009010  0.009010  0.009010\n",
      "Δmacro_f1    -0.011081 -0.011081 -0.011081\n"
     ]
    }
   ],
   "source": [
    "# ===== 0) Install (skip if you already have recent versions) =====\n",
    "# !pip install -U \"transformers>=4.40\" \"datasets>=3.0\" \"accelerate>=0.27\" peft scikit-learn pandas matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, TrainingArguments, Trainer, set_seed\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "DATASET = \"LabHC/bias_in_bios\"\n",
    "TEXT_COL = \"hard_text\"\n",
    "Y_COL    = \"profession\"   # already numeric\n",
    "G_COL    = \"gender\"       # 0 male, 1 female\n",
    "\n",
    "# How small do you want it?\n",
    "TOP_K_PROFESSIONS   = 28     # keep all 28 (set to e.g. 20 to shrink)\n",
    "MAX_PER_GROUP_TRAIN = 800    # cap per (profession, gender) in train\n",
    "MAX_PER_GROUP_DEV   = 200\n",
    "MAX_PER_GROUP_TEST  = 400\n",
    "\n",
    "# Training speed knobs\n",
    "MAX_STEPS    = 150          # hard cap on updates\n",
    "BATCH_TRAIN  = 32\n",
    "BATCH_EVAL   = 64\n",
    "MAX_LEN      = 128           # shorten sequences to speed up\n",
    "LR           = 2e-5\n",
    "SEED         = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"CUDA:\", torch.cuda.is_available(),\n",
    "      torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# ------------------ 1) Load ------------------\n",
    "train_ds = load_dataset(DATASET, split=\"train\")\n",
    "dev_ds   = load_dataset(DATASET, split=\"dev\")\n",
    "test_ds  = load_dataset(DATASET, split=\"test\")\n",
    "print(\"Original sizes:\", len(train_ds), len(dev_ds), len(test_ds))\n",
    "\n",
    "# ------------------ 2) Downsize helpers ------------------\n",
    "def keep_topk(ds, label_col, k):\n",
    "    counts = Counter(ds[label_col])\n",
    "    topk = {lab for lab, _ in counts.most_common(k)}\n",
    "    return ds.filter(lambda ex: ex[label_col] in topk)\n",
    "\n",
    "def stratified_cap(ds, label_col, group_col, cap, seed=42):\n",
    "    df = ds.to_pandas()\n",
    "    df_small = (df.groupby([label_col, group_col], group_keys=False)\n",
    "                  .apply(lambda x: x.sample(n=min(cap, len(x)), random_state=seed))\n",
    "                  .reset_index(drop=True))\n",
    "    return Dataset.from_pandas(df_small, preserve_index=False)\n",
    "\n",
    "# Optional: restrict to top-K professions\n",
    "if TOP_K_PROFESSIONS is not None:\n",
    "    train_ds = keep_topk(train_ds, Y_COL, TOP_K_PROFESSIONS)\n",
    "    dev_ds   = keep_topk(dev_ds,   Y_COL, TOP_K_PROFESSIONS)\n",
    "    test_ds  = keep_topk(test_ds,  Y_COL, TOP_K_PROFESSIONS)\n",
    "\n",
    "# Cap per (profession, gender)\n",
    "train_ds = stratified_cap(train_ds, Y_COL, G_COL, MAX_PER_GROUP_TRAIN)\n",
    "dev_ds   = stratified_cap(dev_ds,   Y_COL, G_COL, MAX_PER_GROUP_DEV)\n",
    "test_ds  = stratified_cap(test_ds,  Y_COL, G_COL, MAX_PER_GROUP_TEST)\n",
    "\n",
    "print(\"Downsized sizes:\", len(train_ds), len(dev_ds), len(test_ds))\n",
    "\n",
    "# ------------------ 3) Make labels contiguous (0..K-1) across ALL splits ------------------\n",
    "all_labels = sorted(set(train_ds[Y_COL]) | set(dev_ds[Y_COL]) | set(test_ds[Y_COL]))\n",
    "need_remap = (all_labels != list(range(len(all_labels)))) or (min(all_labels) != 0)\n",
    "print(\"Labels contiguous?\", not need_remap, \"(#classes =\", len(all_labels), \")\")\n",
    "\n",
    "if need_remap:\n",
    "    label2id = {lab: i for i, lab in enumerate(all_labels)}\n",
    "    def _remap(ex):\n",
    "        ex[Y_COL] = label2id[ex[Y_COL]]\n",
    "        return ex\n",
    "    train_ds = train_ds.map(_remap)\n",
    "    dev_ds   = dev_ds.map(_remap)\n",
    "    test_ds  = test_ds.map(_remap)\n",
    "else:\n",
    "    label2id = {lab: lab for lab in all_labels}\n",
    "\n",
    "num_labels = len(label2id)\n",
    "print(\"num_labels =\", num_labels)\n",
    "\n",
    "# ------------------ 4) Tokenise ------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tok(batch):\n",
    "    enc = tokenizer(batch[TEXT_COL], truncation=True, max_length=MAX_LEN)\n",
    "    enc[\"labels\"]    = batch[Y_COL]\n",
    "    enc[\"gender_id\"] = batch[G_COL]\n",
    "    return enc\n",
    "\n",
    "train_tok = train_ds.map(tok, batched=True, remove_columns=train_ds.column_names)\n",
    "dev_tok   = dev_ds.map(tok,   batched=True, remove_columns=dev_ds.column_names)\n",
    "test_tok  = test_ds.map(tok,  batched=True, remove_columns=test_ds.column_names)\n",
    "\n",
    "# ------------------ 5) Metrics ------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds),\n",
    "            \"macro_f1\": f1_score(labels, preds, average=\"macro\")}\n",
    "\n",
    "def per_gender_scores(labels, preds, genders):\n",
    "    out = {}\n",
    "    for name, gid in [(\"male\", 0), (\"female\", 1)]:\n",
    "        mask = (genders == gid)\n",
    "        if mask.sum() == 0:\n",
    "            out[name] = {\"n\": 0, \"acc\": np.nan, \"macro_f1\": np.nan}\n",
    "            continue\n",
    "        out[name] = {\n",
    "            \"n\": int(mask.sum()),\n",
    "            \"acc\": accuracy_score(labels[mask], preds[mask]),\n",
    "            \"macro_f1\": f1_score(labels[mask], preds[mask], average=\"macro\")\n",
    "        }\n",
    "    out[\"Δacc\"] = out[\"male\"][\"acc\"] - out[\"female\"][\"acc\"]\n",
    "    out[\"Δmacro_f1\"] = out[\"male\"][\"macro_f1\"] - out[\"female\"][\"macro_f1\"]\n",
    "    return out\n",
    "\n",
    "# ------------------ 6) Train (λ = 0) ------------------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=num_labels\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"chk_bios_lambda0_small\",\n",
    "    max_steps=MAX_STEPS,                        # HARD CAP\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    seed=SEED,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=dev_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ------------------ 7) Evaluate ------------------\n",
    "def eval_and_report(split_name, tok_ds):\n",
    "    out = trainer.predict(tok_ds)\n",
    "    preds  = np.argmax(out.predictions, axis=1)\n",
    "    labels = out.label_ids\n",
    "    genders = np.array(tok_ds[\"gender_id\"])\n",
    "    print(f\"\\n=== {split_name.upper()} (overall) ===\")\n",
    "    print(f\"Accuracy : {accuracy_score(labels, preds):.4f}\")\n",
    "    print(f\"Macro-F1 : {f1_score(labels, preds, average='macro'):.4f}\")\n",
    "    fair = per_gender_scores(labels, preds, genders)\n",
    "    print(f\"\\n=== {split_name.upper()} per-gender ===\")\n",
    "    print(pd.DataFrame(fair).T)\n",
    "    return fair\n",
    "\n",
    "dev_fair  = eval_and_report(\"dev\", dev_tok)\n",
    "test_fair = eval_and_report(\"test\", test_tok)\n",
    "\n",
    "os.makedirs(\"results_small_lambda0\", exist_ok=True)\n",
    "pd.DataFrame(dev_fair).T.to_csv(\"results_small_lambda0/dev_fairness.csv\")\n",
    "pd.DataFrame(test_fair).T.to_csv(\"results_small_lambda0/test_fairness.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
