{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca44695",
   "metadata": {},
   "source": [
    "# SEAT: Sentence Encoder Association Test (Contextual Bias in Embeddings)\n",
    "\n",
    "- **[May et al., 2019]**: *\"Measuring Societal Biases in Text Corpora via First-Order Co-occurrence\"*\n",
    "- **[Dev and Phillips, 2019]**: *\"Attenuating Bias in Word Representations with Locally Linear Mapping\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e188de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b29c3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a940a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    \"\"\"\n",
    "    Extract sentence embedding using BERT's [CLS] token representation.\n",
    "    Following the methodology from May et al. (2019).\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # Use [CLS] token representation as sentence embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed0e7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SEAT Test Implementation (May et al., 2019)\n",
    "# =============================================================================\n",
    "\n",
    "# Define sentence templates and target words\n",
    "# Template sets A and B represent gendered contexts\n",
    "A_TEMPLATES = [\n",
    "    \"He is an excellent {}.\",\n",
    "    \"This man is a skilled {}.\",\n",
    "    \"He works as a professional {}.\",\n",
    "    \"This guy is a talented {}.\",\n",
    "    \"He has expertise as a {}.\",\n",
    "    \"This gentleman is a qualified {}.\"\n",
    "]\n",
    "\n",
    "B_TEMPLATES = [\n",
    "    \"She is an excellent {}.\",\n",
    "    \"This woman is a skilled {}.\",\n",
    "    \"She works as a professional {}.\",\n",
    "    \"This girl is a talented {}.\",\n",
    "    \"She has expertise as a {}.\",\n",
    "    \"This lady is a qualified {}.\"\n",
    "]\n",
    "\n",
    "# More stereotypically gendered professions\n",
    "X_WORDS = [\n",
    "    \"engineer\", \"programmer\", \"physicist\", \"mathematician\", \n",
    "    \"scientist\", \"architect\", \"developer\", \"researcher\",\n",
    "    \"technician\", \"analyst\", \"inventor\", \"mechanic\"\n",
    "]\n",
    "\n",
    "Y_WORDS = [\n",
    "    \"nurse\", \"teacher\", \"counselor\", \"therapist\", \n",
    "    \"caregiver\", \"social worker\", \"kindergarten teacher\", \n",
    "    \"babysitter\", \"nanny\", \"childcare worker\", \"aide\", \"assistant\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad7cacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_association(target_word, attribute_templates_1, attribute_templates_2):\n",
    "    \"\"\"\n",
    "    Compute WEAT-style association: s(w, A, B) = mean(cos(w,a)) - mean(cos(w,b))\n",
    "    where w is contextualized in sentences, A and B are attribute templates\n",
    "    \"\"\"\n",
    "    # Generate sentences with target word in both attribute contexts\n",
    "    sentences_1 = [template.format(target_word) for template in attribute_templates_1]\n",
    "    sentences_2 = [template.format(target_word) for template in attribute_templates_2]\n",
    "    \n",
    "    # Get embeddings\n",
    "    embs_1 = [get_sentence_embedding(sent) for sent in sentences_1]\n",
    "    embs_2 = [get_sentence_embedding(sent) for sent in sentences_2]\n",
    "    \n",
    "    # Compute cross-similarities (each sentence with target vs attribute contexts)\n",
    "    similarities_1 = []\n",
    "    similarities_2 = []\n",
    "    \n",
    "    for emb1 in embs_1:\n",
    "        for emb2 in embs_1:\n",
    "            if not np.array_equal(emb1, emb2):  # Don't compare with itself\n",
    "                similarities_1.append(1 - cosine(emb1, emb2))\n",
    "    \n",
    "    for emb1 in embs_2:\n",
    "        for emb2 in embs_2:\n",
    "            if not np.array_equal(emb1, emb2):\n",
    "                similarities_2.append(1 - cosine(emb1, emb2))\n",
    "    \n",
    "    # Association = mean similarity with male contexts - mean similarity with female contexts\n",
    "    return np.mean(similarities_1) - np.mean(similarities_2)\n",
    "\n",
    "def improved_seat_test(X_words, Y_words, male_templates, female_templates):\n",
    "    \"\"\"Improved SEAT test implementation\"\"\"\n",
    "    \n",
    "    # Compute association for each word\n",
    "    X_associations = [weat_association(word, male_templates, female_templates) for word in X_words]\n",
    "    Y_associations = [weat_association(word, male_templates, female_templates) for word in Y_words]\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    X_mean = np.mean(X_associations)\n",
    "    Y_mean = np.mean(Y_associations)\n",
    "    \n",
    "    pooled_std = np.sqrt(((len(X_associations)-1)*np.var(X_associations, ddof=1) + \n",
    "                          (len(Y_associations)-1)*np.var(Y_associations, ddof=1)) / \n",
    "                         (len(X_associations) + len(Y_associations) - 2))\n",
    "    \n",
    "    effect_size = (X_mean - Y_mean) / pooled_std\n",
    "    return effect_size, X_associations, Y_associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "847a2835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. IMPROVED TEMPLATES METHOD:\n",
      "   Effect Size: -1.9954\n",
      "   STEM mean: -0.0241, Care mean: -0.0108\n"
     ]
    }
   ],
   "source": [
    "print(\"1. IMPROVED TEMPLATES METHOD:\")\n",
    "effect1, X_assoc1, Y_assoc1 = improved_seat_test(X_WORDS, Y_WORDS, A_TEMPLATES, B_TEMPLATES)\n",
    "print(f\"   Effect Size: {effect1:.4f}\")\n",
    "print(f\"   STEM mean: {np.mean(X_assoc1):.4f}, Care mean: {np.mean(Y_assoc1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda48eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_sentence_set_embedding(words, templates):\n",
    "#     \"\"\"\n",
    "#     Compute average embedding for a set of sentences formed by combining words with templates.\n",
    "#     \"\"\"\n",
    "#     embeddings = []\n",
    "#     for word in words:\n",
    "#         for template in templates:\n",
    "#             sentence = template.format(word)\n",
    "#             embedding = get_sentence_embedding(sentence)\n",
    "#             embeddings.append(embedding)\n",
    "#     return np.array(embeddings)\n",
    "\n",
    "# def cosine_similarity(a, b):\n",
    "#     \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "#     return 1 - cosine(a, b)\n",
    "\n",
    "def seat_effect_size(X_words, Y_words, A_templates, B_templates):\n",
    "    \"\"\"\n",
    "    Compute SEAT effect size following May et al. (2019) methodology.\n",
    "    \n",
    "    The effect size measures the difference in association between:\n",
    "    - X words (e.g., STEM) with A templates (male) vs B templates (female)\n",
    "    - Y words (e.g., care) with A templates (male) vs B templates (female)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate embeddings for all combinations\n",
    "    X_A_embeddings = compute_sentence_set_embedding(X_words, A_templates)\n",
    "    X_B_embeddings = compute_sentence_set_embedding(X_words, B_templates)\n",
    "    Y_A_embeddings = compute_sentence_set_embedding(Y_words, A_templates)\n",
    "    Y_B_embeddings = compute_sentence_set_embedding(Y_words, B_templates)\n",
    "    \n",
    "    # Compute association scores for each word\n",
    "    X_associations = []\n",
    "    Y_associations = []\n",
    "    \n",
    "    # For X words (STEM)\n",
    "    for i, word in enumerate(X_words):\n",
    "        # Get embeddings for this word with different templates\n",
    "        word_A_embs = X_A_embeddings[i*len(A_templates):(i+1)*len(A_templates)]\n",
    "        word_B_embs = X_B_embeddings[i*len(B_templates):(i+1)*len(B_templates)]\n",
    "        \n",
    "        # Compute average association with A vs B\n",
    "        A_similarity = np.mean([cosine_similarity(emb_a, emb_b) \n",
    "                               for emb_a in word_A_embs for emb_b in word_B_embs])\n",
    "        X_associations.append(A_similarity)\n",
    "    \n",
    "    # For Y words (Care)\n",
    "    for i, word in enumerate(Y_words):\n",
    "        word_A_embs = Y_A_embeddings[i*len(A_templates):(i+1)*len(A_templates)]\n",
    "        word_B_embs = Y_B_embeddings[i*len(B_templates):(i+1)*len(B_templates)]\n",
    "        \n",
    "        A_similarity = np.mean([cosine_similarity(emb_a, emb_b) \n",
    "                               for emb_a in word_A_embs for emb_b in word_B_embs])\n",
    "        Y_associations.append(A_similarity)\n",
    "    \n",
    "    # Compute effect size (Cohen's d)\n",
    "    X_mean = np.mean(X_associations)\n",
    "    Y_mean = np.mean(Y_associations)\n",
    "    pooled_std = np.sqrt(((len(X_associations)-1)*np.var(X_associations, ddof=1) + \n",
    "                          (len(Y_associations)-1)*np.var(Y_associations, ddof=1)) / \n",
    "                         (len(X_associations) + len(Y_associations) - 2))\n",
    "    \n",
    "    effect_size = (X_mean - Y_mean) / pooled_std\n",
    "    return effect_size, X_associations, Y_associations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc72c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(X_words, Y_words, A_templates, B_templates, n_permutations=10):\n",
    "    \"\"\"\n",
    "    Perform permutation test to assess statistical significance.\n",
    "    Following the approach in May et al. (2019).\n",
    "    \"\"\"\n",
    "    # Compute original effect size\n",
    "    original_effect, _, _ = seat_effect_size(X_words, Y_words, A_templates, B_templates)\n",
    "    \n",
    "    # Combine all words for permutation\n",
    "    all_words = X_words + Y_words\n",
    "    n_X = len(X_words)\n",
    "    \n",
    "    permuted_effects = []\n",
    "    for _ in range(n_permutations):\n",
    "        # Randomly shuffle and split\n",
    "        shuffled = np.random.permutation(all_words)\n",
    "        X_perm = shuffled[:n_X].tolist()\n",
    "        Y_perm = shuffled[n_X:].tolist()\n",
    "        \n",
    "        # Compute effect for permuted data\n",
    "        perm_effect, _, _ = seat_effect_size(X_perm, Y_perm, A_templates, B_templates)\n",
    "        permuted_effects.append(perm_effect)\n",
    "    \n",
    "    # Calculate p-value (two-tailed)\n",
    "    p_value = np.mean(np.abs(permuted_effects) >= np.abs(original_effect))\n",
    "    \n",
    "    return original_effect, p_value, permuted_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "013ea73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SEAT effect size...\n",
      "\n",
      "SEAT Results:\n",
      "Effect Size (Cohen's d): -0.3767\n",
      "X (STEM) mean association: 0.8982\n",
      "Y (Care) mean association: 0.9031\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Run SEAT Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Computing SEAT effect size...\")\n",
    "effect_size, X_assoc, Y_assoc = seat_effect_size(X_WORDS, Y_WORDS, A_TEMPLATES, B_TEMPLATES)\n",
    "\n",
    "print(f\"\\nSEAT Results:\")\n",
    "print(f\"Effect Size (Cohen's d): {effect_size:.4f}\")\n",
    "print(f\"X (STEM) mean association: {np.mean(X_assoc):.4f}\")\n",
    "print(f\"Y (Care) mean association: {np.mean(Y_assoc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e6cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running permutation test...\n",
      "Original effect size: -0.3767\n",
      "P-value: 0.5000\n",
      "Statistically significant: No\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Statistical significance test\n",
    "print(\"\\nRunning permutation test...\")\n",
    "original_effect, p_value, permuted_effects = permutation_test(X_WORDS, Y_WORDS, A_TEMPLATES, B_TEMPLATES)\n",
    "\n",
    "print(f\"Original effect size: {original_effect:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Statistically significant: {'Yes' if p_value < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualization\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Effect size distribution from permutation test\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(permuted_effects, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "plt.axvline(original_effect, color='red', linestyle='--', linewidth=2, label=f'Observed: {original_effect:.3f}')\n",
    "plt.xlabel('Effect Size')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Permutation Test Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Association scores by word category\n",
    "plt.subplot(1, 2, 2)\n",
    "x_pos = np.arange(len(X_WORDS))\n",
    "y_pos = np.arange(len(Y_WORDS)) + len(X_WORDS) + 1\n",
    "\n",
    "plt.barh(x_pos, X_assoc, color='skyblue', label='STEM professions', alpha=0.8)\n",
    "plt.barh(y_pos, Y_assoc, color='lightcoral', label='Care professions', alpha=0.8)\n",
    "\n",
    "plt.yticks(list(x_pos) + list(y_pos), X_WORDS + Y_WORDS)\n",
    "plt.xlabel('Association Score')\n",
    "plt.title('Individual Word Associations')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PCA Visualization of Sentence Embeddings\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating PCA visualization...\")\n",
    "\n",
    "# Collect all sentence embeddings with labels\n",
    "all_sentences = []\n",
    "all_labels = []\n",
    "all_embeddings = []\n",
    "\n",
    "for word in X_WORDS + Y_WORDS:\n",
    "    word_type = \"STEM\" if word in X_WORDS else \"Care\"\n",
    "    \n",
    "    for template in A_TEMPLATES:\n",
    "        sentence = template.format(word)\n",
    "        embedding = get_sentence_embedding(sentence)\n",
    "        all_sentences.append(sentence)\n",
    "        all_labels.append(f\"{word} ({word_type}, Male)\")\n",
    "        all_embeddings.append(embedding)\n",
    "    \n",
    "    for template in B_TEMPLATES:\n",
    "        sentence = template.format(word)\n",
    "        embedding = get_sentence_embedding(sentence)\n",
    "        all_sentences.append(sentence)\n",
    "        all_labels.append(f\"{word} ({word_type}, Female)\")\n",
    "        all_embeddings.append(embedding)\n",
    "\n",
    "# PCA reduction\n",
    "embeddings_array = np.array(all_embeddings)\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = {'STEM, Male': 'blue', 'STEM, Female': 'lightblue', \n",
    "          'Care, Male': 'red', 'Care, Female': 'lightcoral'}\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    word, context = label.split(' (', 1)\n",
    "    context = context.rstrip(')')\n",
    "    \n",
    "    x, y = embeddings_2d[i]\n",
    "    plt.scatter(x, y, c=colors[context], alpha=0.7, s=60)\n",
    "    \n",
    "    # Add text labels for clarity (sample a few to avoid clutter)\n",
    "    if i % 8 == 0:  # Show every 8th label to reduce clutter\n",
    "        plt.annotate(f\"{word}\", (x, y), xytext=(5, 5), textcoords='offset points', \n",
    "                    fontsize=8, alpha=0.8)\n",
    "\n",
    "# Create legend\n",
    "for context, color in colors.items():\n",
    "    plt.scatter([], [], c=color, label=context, s=60)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA of Sentence Embeddings: SEAT Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a487d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Interpretation and Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Based on the SEAT analysis following May et al. (2019):\n",
    "\n",
    "1. EFFECT SIZE: {effect_size:.4f}\n",
    "   - Positive values indicate STEM professions are more associated with male contexts\n",
    "   - Negative values would indicate the opposite\n",
    "   - |d| > 0.2 is considered a small effect, |d| > 0.5 medium, |d| > 0.8 large\n",
    "\n",
    "2. STATISTICAL SIGNIFICANCE: p = {p_value:.4f}\n",
    "   - {'Significant' if p_value < 0.05 else 'Not significant'} at α = 0.05 level\n",
    "   - Based on {len(permuted_effects)} random permutations\n",
    "\n",
    "3. PRACTICAL IMPLICATIONS:\n",
    "   - The model {'shows' if abs(effect_size) > 0.2 else 'shows minimal'} gender bias in profession associations\n",
    "   - This bias reflects patterns in the training data\n",
    "   - Higher effect sizes suggest stronger stereotypical associations\n",
    "\n",
    "METHODOLOGY NOTES:\n",
    "- Uses contextual sentence embeddings (BERT [CLS] tokens)\n",
    "- Follows SEAT framework from May et al. (2019)\n",
    "- Statistical significance via permutation testing\n",
    "- Effect size computed as Cohen's d\n",
    "\"\"\")\n",
    "\n",
    "print(\"Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b56a4c56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p_value\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Run test\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m p_value \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEAT-6 Gender Bias Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobserved_stat\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp-value (permutation test): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 68\u001b[0m, in \u001b[0;36mpermutation_test\u001b[1;34m(X, Y, A, B, n_samples, seed)\u001b[0m\n\u001b[0;32m     66\u001b[0m X_perm \u001b[38;5;241m=\u001b[39m all_embeddings[:n]\n\u001b[0;32m     67\u001b[0m Y_perm \u001b[38;5;241m=\u001b[39m all_embeddings[n:]\n\u001b[1;32m---> 68\u001b[0m stat \u001b[38;5;241m=\u001b[39m \u001b[43mtest_statistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_perm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_perm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(stat) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(observed_stat):\n\u001b[0;32m     70\u001b[0m     greater_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[31], line 51\u001b[0m, in \u001b[0;36mtest_statistic\u001b[1;34m(X, Y, A, B)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_statistic\u001b[39m(X, Y, A, B):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum([s(x, A, B) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum([s(y, A, B) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y])\n",
      "Cell \u001b[1;32mIn[31], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_statistic\u001b[39m(X, Y, A, B):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum([s(x, A, B) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum([\u001b[43ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y])\n",
      "Cell \u001b[1;32mIn[31], line 48\u001b[0m, in \u001b[0;36ms\u001b[1;34m(w, A, B)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21ms\u001b[39m(w, A, B):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine(w, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m A]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine(w, b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m B])\n",
      "Cell \u001b[1;32mIn[31], line 48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21ms\u001b[39m(w, A, B):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m A]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine(w, b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m B])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\spatial\\distance.py:670\u001b[0m, in \u001b[0;36mcosine\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\spatial\\distance.py:620\u001b[0m, in \u001b[0;36mcorrelation\u001b[1;34m(u, v, w, centered)\u001b[0m\n\u001b[0;32m    618\u001b[0m     v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m-\u001b[39m vmu\n\u001b[0;32m    619\u001b[0m uv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(u \u001b[38;5;241m*\u001b[39m v, weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[1;32m--> 620\u001b[0m uu \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m vv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39msquare(v), weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[0;32m    622\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m uv \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(uu \u001b[38;5;241m*\u001b[39m vv)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:518\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[0;32m    515\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     avg \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mmean(axis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeepdims_kw)\n\u001b[0;32m    519\u001b[0m     avg_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(avg)\n\u001b[0;32m    520\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg_as_array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg_as_array\u001b[38;5;241m.\u001b[39msize)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:181\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    178\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "# Load BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[0][0].numpy()  # CLS token\n",
    "\n",
    "# Word groups\n",
    "# Extended male and female names\n",
    "male_names = [\"John\", \"Paul\", \"Mike\", \"Kevin\", \"Steve\", \"Greg\", \"Jeff\", \"Bill\",\n",
    "              \"Frank\", \"George\", \"Ron\", \"Chris\", \"Mark\", \"Dan\", \"Tom\", \"Josh\"]\n",
    "female_names = [\"Amy\", \"Joan\", \"Lisa\", \"Sarah\", \"Diana\", \"Kate\", \"Ann\", \"Donna\",\n",
    "                \"Emily\", \"Julia\", \"Rachel\", \"Karen\", \"Tina\", \"Laura\", \"Jessica\", \"Natalie\"]\n",
    "\n",
    "# Extended career and family words\n",
    "career_words = [\"executive\", \"management\", \"professional\", \"corporation\", \"salary\", \"office\",\n",
    "                \"business\", \"career\", \"entrepreneur\", \"employee\", \"supervisor\", \"director\",\n",
    "                \"consultant\", \"analyst\", \"finance\", \"marketing\"]\n",
    "family_words = [\"home\", \"parents\", \"children\", \"family\", \"cousins\", \"marriage\", \"wedding\",\n",
    "                \"relatives\", \"mom\", \"dad\", \"babysitter\", \"nursery\", \"housewife\", \"grandparents\", \"aunt\", \"uncle\"]\n",
    "\n",
    "\n",
    "# Apply sentence template\n",
    "def apply_template(word):\n",
    "    return f\"This is about {word}.\"\n",
    "\n",
    "def get_group_embeddings(words):\n",
    "    return np.array([get_sentence_embedding(apply_template(w)) for w in words])\n",
    "\n",
    "# Get embeddings\n",
    "X = get_group_embeddings(male_names)\n",
    "Y = get_group_embeddings(female_names)\n",
    "A = get_group_embeddings(career_words)\n",
    "B = get_group_embeddings(family_words)\n",
    "\n",
    "# Differential association function\n",
    "def s(w, A, B):\n",
    "    return np.mean([1 - cosine(w, a) for a in A]) - np.mean([1 - cosine(w, b) for b in B])\n",
    "\n",
    "def test_statistic(X, Y, A, B):\n",
    "    return np.sum([s(x, A, B) for x in X]) - np.sum([s(y, A, B) for y in Y])\n",
    "\n",
    "# Observed test statistic\n",
    "observed_stat = test_statistic(X, Y, A, B)\n",
    "\n",
    "# Permutation test\n",
    "def permutation_test(X, Y, A, B, n_samples=10000, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    all_embeddings = np.concatenate([X, Y])\n",
    "    n = len(X)\n",
    "    greater_count = 0\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        np.random.shuffle(all_embeddings)\n",
    "        X_perm = all_embeddings[:n]\n",
    "        Y_perm = all_embeddings[n:]\n",
    "        stat = test_statistic(X_perm, Y_perm, A, B)\n",
    "        if abs(stat) >= abs(observed_stat):\n",
    "            greater_count += 1\n",
    "\n",
    "    p_value = greater_count / n_samples\n",
    "    return p_value\n",
    "\n",
    "# Run test\n",
    "p_value = permutation_test(X, Y, A, B, n_samples=10000)\n",
    "print(f\"SEAT-6 Gender Bias Score: {observed_stat:.4f}\")\n",
    "print(f\"p-value (permutation test): {p_value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
