{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e7d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification, BertModel,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import stats\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# =============================================================================\n",
    "# A1. SETUP & DATA PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "def load_sst2_dataset():\n",
    "    \"\"\"Load SST-2 dataset from HuggingFace\"\"\"\n",
    "    dataset = load_dataset(\"glue\", \"sst2\")\n",
    "    return dataset\n",
    "\n",
    "def create_demographic_names():\n",
    "    \"\"\"Create lists of male and female names for demographic analysis\"\"\"\n",
    "    male_names = [\n",
    "        \"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Richard\", \n",
    "        \"Joseph\", \"Thomas\", \"Christopher\", \"Charles\", \"Daniel\", \"Matthew\", \n",
    "        \"Anthony\", \"Mark\", \"Donald\", \"Steven\", \"Paul\", \"Andrew\", \"Joshua\"\n",
    "    ]\n",
    "    \n",
    "    female_names = [\n",
    "        \"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\", \"Barbara\", \n",
    "        \"Susan\", \"Jessica\", \"Sarah\", \"Karen\", \"Nancy\", \"Lisa\", \"Betty\", \n",
    "        \"Helen\", \"Sandra\", \"Donna\", \"Carol\", \"Ruth\", \"Sharon\", \"Michelle\"\n",
    "    ]\n",
    "    \n",
    "    return male_names, female_names\n",
    "\n",
    "def detect_demographic_mentions(text, male_names, female_names):\n",
    "    \"\"\"\n",
    "    Detect if text contains demographic mentions (names or pronouns)\n",
    "    Returns: 'male', 'female', or 'neutral'\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Check for names\n",
    "    for name in male_names:\n",
    "        if name.lower() in text_lower:\n",
    "            return 'male'\n",
    "    \n",
    "    for name in female_names:\n",
    "        if name.lower() in text_lower:\n",
    "            return 'female'\n",
    "    \n",
    "    # Check for pronouns\n",
    "    male_pronouns = ['he', 'his', 'him', 'himself']\n",
    "    female_pronouns = ['she', 'her', 'hers', 'herself']\n",
    "    \n",
    "    # Use word boundaries to avoid partial matches\n",
    "    for pronoun in male_pronouns:\n",
    "        if re.search(r'\\b' + pronoun + r'\\b', text_lower):\n",
    "            return 'male'\n",
    "    \n",
    "    for pronoun in female_pronouns:\n",
    "        if re.search(r'\\b' + pronoun + r'\\b', text_lower):\n",
    "            return 'female'\n",
    "    \n",
    "    return 'neutral'\n",
    "\n",
    "def create_demographic_annotated_dataset(dataset, male_names, female_names):\n",
    "    \"\"\"Add demographic annotations to SST-2 dataset\"\"\"\n",
    "    \n",
    "    def add_demographic_info(example):\n",
    "        demographic = detect_demographic_mentions(example['sentence'], male_names, female_names)\n",
    "        example['demographic'] = demographic\n",
    "        return example\n",
    "    \n",
    "    # Annotate all splits\n",
    "    annotated_dataset = {}\n",
    "    for split_name in dataset.keys():\n",
    "        annotated_dataset[split_name] = dataset[split_name].map(add_demographic_info)\n",
    "    \n",
    "    return annotated_dataset\n",
    "\n",
    "def create_demographic_test_sets(annotated_dataset, test_split_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Create separate test sets for demographic analysis\n",
    "    \n",
    "    Since GLUE test set has no labels, we split training data to create\n",
    "    a proper test set with demographic annotations and ground truth labels.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Convert training data to pandas for easier splitting\n",
    "    train_data = annotated_dataset['train']\n",
    "    \n",
    "    # Extract data for splitting\n",
    "    sentences = list(train_data['sentence'])\n",
    "    labels = list(train_data['label'])\n",
    "    demographics = list(train_data['demographic'])\n",
    "    \n",
    "    # Stratified split to maintain label distribution\n",
    "    train_sentences, test_sentences, train_labels, test_labels, train_demos, test_demos = train_test_split(\n",
    "        sentences, labels, demographics,\n",
    "        test_size=test_split_ratio,\n",
    "        stratify=labels,  # Maintain sentiment label balance\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create new train/test datasets\n",
    "    new_train_data = Dataset.from_dict({\n",
    "        'sentence': train_sentences,\n",
    "        'label': train_labels,\n",
    "        'demographic': train_demos\n",
    "    })\n",
    "    \n",
    "    test_data = Dataset.from_dict({\n",
    "        'sentence': test_sentences,\n",
    "        'label': test_labels,\n",
    "        'demographic': test_demos\n",
    "    })\n",
    "    \n",
    "    # Split test data by demographic groups\n",
    "    male_examples = test_data.filter(lambda x: x['demographic'] == 'male')\n",
    "    female_examples = test_data.filter(lambda x: x['demographic'] == 'female')\n",
    "    neutral_examples = test_data.filter(lambda x: x['demographic'] == 'neutral')\n",
    "    \n",
    "    demographic_splits = {\n",
    "        'male': male_examples,\n",
    "        'female': female_examples,\n",
    "        'neutral': neutral_examples,\n",
    "        'all': test_data\n",
    "    }\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"Demographic distribution in test set:\")\n",
    "    for demo, data in demographic_splits.items():\n",
    "        print(f\"  {demo}: {len(data)} examples\")\n",
    "    \n",
    "    print(f\"\\nDataset split summary:\")\n",
    "    print(f\"  Original train: {len(annotated_dataset['train'])} examples\")\n",
    "    print(f\"  New train: {len(new_train_data)} examples\")\n",
    "    print(f\"  New test: {len(test_data)} examples\")\n",
    "    print(f\"  Validation (for eval): {len(annotated_dataset['validation'])} examples\")\n",
    "    \n",
    "    # Update the annotated dataset with new split\n",
    "    annotated_dataset['train'] = new_train_data\n",
    "    annotated_dataset['test'] = test_data\n",
    "    \n",
    "    return demographic_splits, annotated_dataset\n",
    "\n",
    "def create_mini_seat_examples():\n",
    "    \"\"\"Create lightweight SEAT examples for frequent bias measurement\"\"\"\n",
    "    \n",
    "    # Target groups: Male and female names in simple contexts\n",
    "    male_names = [\"James\", \"John\", \"Robert\", \"Michael\"]\n",
    "    female_names = [\"Mary\", \"Patricia\", \"Jennifer\", \"Linda\"]\n",
    "    \n",
    "    male_sentences = [f\"{name} is a person.\" for name in male_names]\n",
    "    female_sentences = [f\"{name} is a person.\" for name in female_names]\n",
    "    \n",
    "    # Attribute groups: Career vs. family oriented (simplified)\n",
    "    career_attributes = [\n",
    "        \"The executive makes decisions.\",\n",
    "        \"The engineer solves problems.\", \n",
    "        \"The manager leads teams.\",\n",
    "        \"The analyst studies data.\"\n",
    "    ]\n",
    "    \n",
    "    family_attributes = [\n",
    "        \"The caregiver helps others.\",\n",
    "        \"The teacher nurtures students.\",\n",
    "        \"The nurse provides care.\",\n",
    "        \"The assistant offers support.\"\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        'male_targets': male_sentences,\n",
    "        'female_targets': female_sentences,\n",
    "        'career_attributes': career_attributes,\n",
    "        'family_attributes': family_attributes\n",
    "    }\n",
    "\n",
    "def preprocess_sst2_for_training(dataset, tokenizer, max_length=128):\n",
    "    \"\"\"Preprocess SST-2 data for training\"\"\"\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples['sentence'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = {}\n",
    "    for split_name in ['train', 'validation']:\n",
    "        if split_name in dataset:\n",
    "            # Get current columns to determine which ones to remove\n",
    "            current_columns = dataset[split_name].column_names\n",
    "            columns_to_remove = [col for col in current_columns if col not in ['label']]\n",
    "            \n",
    "            tokenized_dataset[split_name] = dataset[split_name].map(\n",
    "                tokenize_function,\n",
    "                batched=True,\n",
    "                remove_columns=columns_to_remove\n",
    "            )\n",
    "    \n",
    "    return tokenized_dataset\n",
    "\n",
    "# =============================================================================\n",
    "# A2. BIAS MEASUREMENT FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_sentence_embedding(text, model, tokenizer, pooling='cls'):\n",
    "    \"\"\"Extract sentence embedding from model\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, \n",
    "                      truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Handle both base BERT and sequence classification models\n",
    "        if hasattr(model, 'bert'):\n",
    "            outputs = model.bert(**inputs)\n",
    "        else:\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            outputs = outputs.hidden_states[-1] if hasattr(outputs, 'hidden_states') else outputs.last_hidden_state\n",
    "        \n",
    "        if hasattr(outputs, 'last_hidden_state'):\n",
    "            hidden_states = outputs.last_hidden_state[0]\n",
    "        else:\n",
    "            hidden_states = outputs[0]\n",
    "    \n",
    "    if pooling == 'cls':\n",
    "        return hidden_states[0].cpu().numpy()\n",
    "    elif pooling == 'mean':\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "        masked_embeddings = hidden_states * attention_mask.unsqueeze(-1)\n",
    "        return (masked_embeddings.sum(dim=0) / attention_mask.sum()).cpu().numpy()\n",
    "\n",
    "def calculate_mini_seat_score(seat_examples, model, tokenizer):\n",
    "    \"\"\"Calculate SEAT bias score for current model state\"\"\"\n",
    "    \n",
    "    # Get embeddings for all groups\n",
    "    male_embeddings = [get_sentence_embedding(sent, model, tokenizer) \n",
    "                      for sent in seat_examples['male_targets']]\n",
    "    female_embeddings = [get_sentence_embedding(sent, model, tokenizer) \n",
    "                        for sent in seat_examples['female_targets']]\n",
    "    career_embeddings = [get_sentence_embedding(sent, model, tokenizer) \n",
    "                        for sent in seat_examples['career_attributes']]\n",
    "    family_embeddings = [get_sentence_embedding(sent, model, tokenizer) \n",
    "                        for sent in seat_examples['family_attributes']]\n",
    "    \n",
    "    # Calculate association scores\n",
    "    male_scores = []\n",
    "    female_scores = []\n",
    "    \n",
    "    for male_emb in male_embeddings:\n",
    "        career_sim = np.mean([cosine_similarity([male_emb], [career_emb])[0][0] \n",
    "                             for career_emb in career_embeddings])\n",
    "        family_sim = np.mean([cosine_similarity([male_emb], [family_emb])[0][0] \n",
    "                             for family_emb in family_embeddings])\n",
    "        male_scores.append(career_sim - family_sim)\n",
    "    \n",
    "    for female_emb in female_embeddings:\n",
    "        career_sim = np.mean([cosine_similarity([female_emb], [career_emb])[0][0] \n",
    "                             for career_emb in career_embeddings])\n",
    "        family_sim = np.mean([cosine_similarity([female_emb], [family_emb])[0][0] \n",
    "                             for family_emb in family_embeddings])\n",
    "        female_scores.append(career_sim - family_sim)\n",
    "    \n",
    "    # Calculate effect size\n",
    "    mean_diff = np.mean(male_scores) - np.mean(female_scores)\n",
    "    pooled_std = np.sqrt((np.var(male_scores) + np.var(female_scores)) / 2)\n",
    "    effect_size = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    return effect_size, male_scores, female_scores\n",
    "\n",
    "def evaluate_demographic_performance(model, tokenizer, demographic_test_sets):\n",
    "    \"\"\"Evaluate model performance across demographic groups\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for demographic, test_data in demographic_test_sets.items():\n",
    "        if len(test_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        confidences = []\n",
    "        \n",
    "        model.eval()\n",
    "        for example in test_data:\n",
    "            inputs = tokenizer(\n",
    "                example['sentence'],\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                prediction = torch.argmax(logits, dim=-1).item()\n",
    "                confidence = torch.max(probs).item()\n",
    "                \n",
    "                predictions.append(prediction)\n",
    "                true_labels.append(example['label'])\n",
    "                confidences.append(confidence)\n",
    "        \n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        avg_confidence = np.mean(confidences)\n",
    "        \n",
    "        results[demographic] = {\n",
    "            'accuracy': accuracy,\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'n_examples': len(test_data),\n",
    "            'predictions': predictions,\n",
    "            'true_labels': true_labels,\n",
    "            'confidences': confidences\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def measure_current_bias_state(model, tokenizer, seat_examples, demographic_test_sets):\n",
    "    \"\"\"Comprehensive bias measurement at current model state\"\"\"\n",
    "    \n",
    "    # SEAT bias measurement\n",
    "    seat_effect_size, male_scores, female_scores = calculate_mini_seat_score(\n",
    "        seat_examples, model, tokenizer\n",
    "    )\n",
    "    \n",
    "    # Demographic performance evaluation\n",
    "    demographic_results = evaluate_demographic_performance(\n",
    "        model, tokenizer, demographic_test_sets\n",
    "    )\n",
    "    \n",
    "    # Calculate performance gaps\n",
    "    performance_gaps = {}\n",
    "    if 'male' in demographic_results and 'female' in demographic_results:\n",
    "        male_acc = demographic_results['male']['accuracy']\n",
    "        female_acc = demographic_results['female']['accuracy']\n",
    "        male_conf = demographic_results['male']['avg_confidence']\n",
    "        female_conf = demographic_results['female']['avg_confidence']\n",
    "        \n",
    "        performance_gaps = {\n",
    "            'accuracy_gap': male_acc - female_acc,\n",
    "            'confidence_gap': male_conf - female_conf,\n",
    "            'male_accuracy': male_acc,\n",
    "            'female_accuracy': female_acc\n",
    "        }\n",
    "    \n",
    "    bias_state = {\n",
    "        'seat_effect_size': seat_effect_size,\n",
    "        'seat_male_scores': male_scores,\n",
    "        'seat_female_scores': female_scores,\n",
    "        'demographic_performance': demographic_results,\n",
    "        'performance_gaps': performance_gaps\n",
    "    }\n",
    "    \n",
    "    return bias_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96064b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# A2. FINE-TUNING WITH BIAS TRACKING\n",
    "# =============================================================================\n",
    "\n",
    "def create_bias_tracking_trainer(model, tokenizer, train_dataset, eval_dataset, \n",
    "                                seat_examples, demographic_test_sets, \n",
    "                                bias_check_steps=100, output_dir=\"./bias_tracking_results\"):\n",
    "    \"\"\"Create trainer with bias tracking callbacks\"\"\"\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        eval_steps=200,\n",
    "        eval_strategy=\"steps\",  # Updated parameter name\n",
    "        save_steps=200,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "    \n",
    "    # Store bias tracking data\n",
    "    bias_trajectory = {}\n",
    "    \n",
    "    class BiasTrackingCallback:\n",
    "        def __init__(self):\n",
    "            self.step_count = 0\n",
    "            \n",
    "        def on_step_end(self, args, state, control, model=None, **kwargs):\n",
    "            self.step_count += 1\n",
    "            \n",
    "            # Check bias every N steps\n",
    "            if self.step_count % bias_check_steps == 0:\n",
    "                print(f\"\\n📊 Measuring bias at step {int(state.global_step)}...\")\n",
    "                \n",
    "                bias_state = measure_current_bias_state(\n",
    "                    model, tokenizer, seat_examples, demographic_test_sets\n",
    "                )\n",
    "                \n",
    "                bias_trajectory[int(state.global_step)] = {\n",
    "                    'step': int(state.global_step),\n",
    "                    'epoch': float(state.epoch),\n",
    "                    'bias_state': bias_state,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                # Print current bias metrics\n",
    "                seat_score = bias_state['seat_effect_size']\n",
    "                perf_gaps = bias_state['performance_gaps']\n",
    "                \n",
    "                print(f\"   SEAT Effect Size: {seat_score:.4f}\")\n",
    "                if perf_gaps:\n",
    "                    print(f\"   Accuracy Gap: {perf_gaps['accuracy_gap']:.4f}\")\n",
    "                    print(f\"   Confidence Gap: {perf_gaps['confidence_gap']:.4f}\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[BiasTrackingCallback()]\n",
    "    )\n",
    "    \n",
    "    # Make bias_trajectory accessible\n",
    "    trainer.bias_trajectory = bias_trajectory\n",
    "    \n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # A3. BIAS EVOLUTION ANALYSIS\n",
    "# # =============================================================================\n",
    "\n",
    "# def plot_bias_evolution(bias_trajectory, output_dir=\"./bias_tracking_results\"):\n",
    "#     \"\"\"Plot how bias evolves during training\"\"\"\n",
    "    \n",
    "#     if not bias_trajectory:\n",
    "#         print(\"No bias trajectory data to plot!\")\n",
    "#         return\n",
    "    \n",
    "#     # Extract data for plotting\n",
    "#     steps = []\n",
    "#     seat_scores = []\n",
    "#     accuracy_gaps = []\n",
    "#     confidence_gaps = []\n",
    "    \n",
    "#     for step, data in sorted(bias_trajectory.items(), key=lambda x: int(x[0])):\n",
    "#         steps.append(int(step))\n",
    "#         seat_scores.append(float(data['bias_state']['seat_effect_size']))\n",
    "        \n",
    "#         if data['bias_state']['performance_gaps']:\n",
    "#             accuracy_gaps.append(float(data['bias_state']['performance_gaps']['accuracy_gap']))\n",
    "#             confidence_gaps.append(float(data['bias_state']['performance_gaps']['confidence_gap']))\n",
    "#         else:\n",
    "#             accuracy_gaps.append(0.0)\n",
    "#             confidence_gaps.append(0.0)\n",
    "    \n",
    "#     # Create subplots\n",
    "#     fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "#     # Plot 1: SEAT Effect Size Evolution\n",
    "#     ax1.plot(steps, seat_scores, 'b-o', linewidth=2, markersize=6)\n",
    "#     ax1.set_xlabel('Training Step')\n",
    "#     ax1.set_ylabel('SEAT Effect Size')\n",
    "#     ax1.set_title('SEAT Bias Evolution During Fine-tuning')\n",
    "#     ax1.grid(True, alpha=0.3)\n",
    "#     ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "#     # Add trend annotation\n",
    "#     if len(seat_scores) > 1:\n",
    "#         trend = \"Increasing\" if seat_scores[-1] > seat_scores[0] else \"Decreasing\"\n",
    "#         change = abs(seat_scores[-1] - seat_scores[0])\n",
    "#         ax1.text(0.05, 0.95, f'Trend: {trend}\\nChange: {change:.3f}', \n",
    "#                 transform=ax1.transAxes, verticalalignment='top',\n",
    "#                 bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    \n",
    "#     # Plot 2: Accuracy Gap Evolution\n",
    "#     ax2.plot(steps, accuracy_gaps, 'r-s', linewidth=2, markersize=6)\n",
    "#     ax2.set_xlabel('Training Step')\n",
    "#     ax2.set_ylabel('Accuracy Gap (Male - Female)')\n",
    "#     ax2.set_title('Performance Gap Evolution During Fine-tuning')\n",
    "#     ax2.grid(True, alpha=0.3)\n",
    "#     ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "#     # Plot 3: Confidence Gap Evolution\n",
    "#     ax3.plot(steps, confidence_gaps, 'g-^', linewidth=2, markersize=6)\n",
    "#     ax3.set_xlabel('Training Step')\n",
    "#     ax3.set_ylabel('Confidence Gap (Male - Female)')\n",
    "#     ax3.set_title('Confidence Gap Evolution During Fine-tuning')\n",
    "#     ax3.grid(True, alpha=0.3)\n",
    "#     ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "#     # Plot 4: Combined Evolution\n",
    "#     ax4_twin = ax4.twinx()\n",
    "    \n",
    "#     line1 = ax4.plot(steps, seat_scores, 'b-o', linewidth=2, label='SEAT Effect Size')\n",
    "#     line2 = ax4_twin.plot(steps, accuracy_gaps, 'r-s', linewidth=2, label='Accuracy Gap')\n",
    "    \n",
    "#     ax4.set_xlabel('Training Step')\n",
    "#     ax4.set_ylabel('SEAT Effect Size', color='b')\n",
    "#     ax4_twin.set_ylabel('Accuracy Gap', color='r')\n",
    "#     ax4.set_title('Combined Bias Evolution')\n",
    "#     ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "#     # Combined legend\n",
    "#     lines = line1 + line2\n",
    "#     labels = [l.get_label() for l in lines]\n",
    "#     ax4.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"{output_dir}/bias_evolution_plots.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# def analyze_bias_propagation_patterns(bias_trajectory, initial_bias_state, final_bias_state):\n",
    "#     \"\"\"Analyze patterns in bias propagation\"\"\"\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(\"📈 BIAS PROPAGATION ANALYSIS\")\n",
    "#     print(\"=\"*60)\n",
    "    \n",
    "#     # Extract trajectory data\n",
    "#     steps = sorted([int(k) for k in bias_trajectory.keys()])\n",
    "#     seat_scores = [float(bias_trajectory[str(step)]['bias_state']['seat_effect_size']) for step in steps]\n",
    "    \n",
    "#     initial_seat = initial_bias_state['seat_effect_size']\n",
    "#     final_seat = final_bias_state['seat_effect_size']\n",
    "    \n",
    "#     print(f\"\\n🎯 OVERALL BIAS CHANGE:\")\n",
    "#     print(f\"   Initial SEAT Score: {initial_seat:.4f}\")\n",
    "#     print(f\"   Final SEAT Score:   {final_seat:.4f}\")\n",
    "#     print(f\"   Total Change:       {final_seat - initial_seat:.4f}\")\n",
    "#     print(f\"   Percent Change:     {((final_seat - initial_seat) / abs(initial_seat) * 100):.1f}%\")\n",
    "    \n",
    "#     # Analyze trend\n",
    "#     if len(seat_scores) > 1:\n",
    "#         # Calculate slope\n",
    "#         x = np.array(steps)\n",
    "#         y = np.array(seat_scores)\n",
    "#         slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        \n",
    "#         print(f\"\\n📊 BIAS TRAJECTORY ANALYSIS:\")\n",
    "#         print(f\"   Slope:              {slope:.6f}\")\n",
    "#         print(f\"   R-squared:          {r_value**2:.4f}\")\n",
    "#         print(f\"   P-value:            {p_value:.6f}\")\n",
    "#         print(f\"   Trend Direction:    {'Bias Amplification' if slope > 0 else 'Bias Reduction'}\")\n",
    "#         print(f\"   Trend Strength:     {'Strong' if r_value**2 > 0.7 else 'Moderate' if r_value**2 > 0.3 else 'Weak'}\")\n",
    "    \n",
    "#     # Identify critical phases\n",
    "#     if len(seat_scores) > 2:\n",
    "#         # Find largest changes between consecutive measurements\n",
    "#         changes = [seat_scores[i+1] - seat_scores[i] for i in range(len(seat_scores)-1)]\n",
    "#         max_change_idx = np.argmax(np.abs(changes))\n",
    "#         max_change = changes[max_change_idx]\n",
    "#         critical_step = steps[max_change_idx]\n",
    "        \n",
    "#         print(f\"\\n⚡ CRITICAL TRAINING PHASE:\")\n",
    "#         print(f\"   Largest Change:     {max_change:.4f}\")\n",
    "#         print(f\"   Occurred at Step:   {critical_step}\")\n",
    "#         print(f\"   Phase Description:  {'Bias Spike' if max_change > 0 else 'Bias Drop'}\")\n",
    "    \n",
    "#     # Performance gap analysis\n",
    "#     if initial_bias_state['performance_gaps'] and final_bias_state['performance_gaps']:\n",
    "#         initial_gap = initial_bias_state['performance_gaps']['accuracy_gap']\n",
    "#         final_gap = final_bias_state['performance_gaps']['accuracy_gap']\n",
    "        \n",
    "#         print(f\"\\n🎭 PERFORMANCE DISPARITY ANALYSIS:\")\n",
    "#         print(f\"   Initial Accuracy Gap: {initial_gap:.4f}\")\n",
    "#         print(f\"   Final Accuracy Gap:   {final_gap:.4f}\")\n",
    "#         print(f\"   Gap Change:           {final_gap - initial_gap:.4f}\")\n",
    "        \n",
    "#         # Correlation between SEAT and performance gaps\n",
    "#         perf_gaps = []\n",
    "#         for step in steps:\n",
    "#             step_data = bias_trajectory[str(step)]\n",
    "#             if step_data['bias_state']['performance_gaps']:\n",
    "#                 perf_gaps.append(float(step_data['bias_state']['performance_gaps']['accuracy_gap']))\n",
    "#             else:\n",
    "#                 perf_gaps.append(0.0)\n",
    "        \n",
    "#         if len(perf_gaps) == len(seat_scores) and len(seat_scores) > 1:\n",
    "#             correlation, p_val = stats.pearsonr(seat_scores, perf_gaps)\n",
    "#             print(f\"   SEAT-Performance Correlation: {correlation:.4f} (p={p_val:.4f})\")\n",
    "    \n",
    "#     # Summary insights\n",
    "#     print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "    \n",
    "#     if abs(final_seat - initial_seat) > 0.5:\n",
    "#         print(f\"   • SIGNIFICANT bias change detected during fine-tuning\")\n",
    "#     else:\n",
    "#         print(f\"   • Relatively STABLE bias during fine-tuning\")\n",
    "    \n",
    "#     if final_seat > initial_seat:\n",
    "#         print(f\"   • Fine-tuning AMPLIFIED pre-existing bias\")\n",
    "#     else:\n",
    "#         print(f\"   • Fine-tuning REDUCED pre-existing bias\")\n",
    "    \n",
    "#     if len(seat_scores) > 1 and r_value**2 > 0.5:\n",
    "#         print(f\"   • SYSTEMATIC bias evolution pattern detected\")\n",
    "#     else:\n",
    "#         print(f\"   • IRREGULAR bias evolution pattern\")\n",
    "    \n",
    "#     return {\n",
    "#         'bias_change': float(final_seat - initial_seat),\n",
    "#         'percent_change': float(((final_seat - initial_seat) / abs(initial_seat) * 100) if initial_seat != 0 else 0),\n",
    "#         'trend_slope': float(slope) if len(seat_scores) > 1 else None,\n",
    "#         'trend_r_squared': float(r_value**2) if len(seat_scores) > 1 else None,\n",
    "#         'critical_step': int(critical_step) if len(seat_scores) > 2 else None,\n",
    "#         'max_change': float(max_change) if len(seat_scores) > 2 else None\n",
    "#     }\n",
    "\n",
    "# def generate_bias_propagation_report(results, output_dir=\"./bias_tracking_results\"):\n",
    "#     \"\"\"Generate comprehensive bias propagation report\"\"\"\n",
    "    \n",
    "#     bias_trajectory = results['bias_trajectory']\n",
    "#     initial_bias_state = results['initial_bias_state']\n",
    "#     final_bias_state = results['final_bias_state']\n",
    "    \n",
    "#     # Create visualizations\n",
    "#     print(\"📊 Generating bias evolution plots...\")\n",
    "#     plot_bias_evolution(bias_trajectory, output_dir)\n",
    "    \n",
    "#     # Analyze patterns\n",
    "#     print(\"🔍 Analyzing bias propagation patterns...\")\n",
    "#     propagation_analysis = analyze_bias_propagation_patterns(\n",
    "#         bias_trajectory, initial_bias_state, final_bias_state\n",
    "#     )\n",
    "    \n",
    "#     # Create summary report\n",
    "#     report = {\n",
    "#         'experiment_summary': {\n",
    "#             'total_training_steps': max(bias_trajectory.keys()) if bias_trajectory else 0,\n",
    "#             'bias_measurements_taken': len(bias_trajectory),\n",
    "#             'initial_seat_score': initial_bias_state['seat_effect_size'],\n",
    "#             'final_seat_score': final_bias_state['seat_effect_size']\n",
    "#         },\n",
    "#         'propagation_analysis': propagation_analysis,\n",
    "#         'recommendations': []\n",
    "#     }\n",
    "    \n",
    "#     # Generate recommendations\n",
    "#     if propagation_analysis['bias_change'] > 0.5:\n",
    "#         report['recommendations'].append(\"URGENT: Bias amplification detected - apply debiasing methods\")\n",
    "#     elif propagation_analysis['bias_change'] > 0.1:\n",
    "#         report['recommendations'].append(\"MODERATE: Monitor bias and consider intervention\")\n",
    "#     else:\n",
    "#         report['recommendations'].append(\"STABLE: Current fine-tuning approach acceptable\")\n",
    "    \n",
    "#     if propagation_analysis.get('trend_r_squared', 0) > 0.7:\n",
    "#         report['recommendations'].append(\"SYSTEMATIC: Bias evolution is predictable - early intervention possible\")\n",
    "    \n",
    "#     if propagation_analysis.get('critical_step'):\n",
    "#         report['recommendations'].append(f\"TIMING: Focus intervention around step {propagation_analysis['critical_step']}\")\n",
    "    \n",
    "#     # Save comprehensive report\n",
    "#     with open(f\"{output_dir}/bias_propagation_report.json\", 'w') as f:\n",
    "#         json.dump(report, f, indent=2)\n",
    "    \n",
    "#     print(f\"\\n✅ Complete bias propagation report saved to {output_dir}/\")\n",
    "#     return report\n",
    "\n",
    "# # =============================================================================\n",
    "# # MAIN EXECUTION FUNCTION\n",
    "# # =============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d93831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Bias Propagation Tracking Analysis\n",
      "============================================================\n",
      "📋 Step 1: Loading data and models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer_name='bert-base-uncased'\n",
    "output_dir=\"./bias_tracking_results\"\n",
    "\n",
    "print(\"🚀 Starting Bias Propagation Tracking Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Setup\n",
    "print(\"📋 Step 1: Loading data and models...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n",
    "model = BertForSequenceClassification.from_pretrained(tokenizer_name, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd296650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 134523.98 examples/s]\n",
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 112014.42 examples/s]\n",
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 161139.03 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic distribution in test set:\n",
      "  male: 517 examples\n",
      "  female: 156 examples\n",
      "  neutral: 9430 examples\n",
      "  all: 10103 examples\n",
      "\n",
      "Dataset split summary:\n",
      "  Original train: 67349 examples\n",
      "  New train: 57246 examples\n",
      "  New test: 10103 examples\n",
      "  Validation (for eval): 872 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 57246/57246 [00:30<00:00, 1889.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and prepare data\n",
    "sst2_dataset = load_sst2_dataset()\n",
    "male_names, female_names = create_demographic_names()\n",
    "annotated_dataset = create_demographic_annotated_dataset(sst2_dataset, male_names, female_names)\n",
    "demographic_test_sets, annotated_dataset = create_demographic_test_sets(annotated_dataset)\n",
    "\n",
    "# Prepare training data (now using the new train split)\n",
    "tokenized_dataset = preprocess_sst2_for_training(annotated_dataset, tokenizer)\n",
    "train_dataset = tokenized_dataset['train']\n",
    "eval_dataset = tokenized_dataset['validation']  # Use original validation for evaluation\n",
    "\n",
    "# Create SEAT examples\n",
    "seat_examples = create_mini_seat_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Step 2: Measuring initial bias state...\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 Step 2: Measuring initial bias state...\")\n",
    "initial_bias_state = measure_current_bias_state(\n",
    "    model, tokenizer, seat_examples, demographic_test_sets\n",
    ")\n",
    "\n",
    "print(f\"   Initial SEAT Effect Size: {initial_bias_state['seat_effect_size']:.4f}\")\n",
    "if initial_bias_state['performance_gaps']:\n",
    "    print(f\"   Initial Accuracy Gap: {initial_bias_state['performance_gaps']['accuracy_gap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4845e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏋️ Step 3: Starting fine-tuning with bias tracking...\")\n",
    "trainer = create_bias_tracking_trainer(\n",
    "    model, tokenizer, train_dataset, eval_dataset,\n",
    "    seat_examples, demographic_test_sets,\n",
    "    bias_check_steps=100,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Step 4: Measuring final bias state...\")\n",
    "final_bias_state = measure_current_bias_state(\n",
    "    model, tokenizer, seat_examples, demographic_test_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Final SEAT Effect Size: {final_bias_state['seat_effect_size']:.4f}\")\n",
    "if final_bias_state['performance_gaps']:\n",
    "    print(f\"   Final Accuracy Gap: {final_bias_state['performance_gaps']['accuracy_gap']:.4f}\")\n",
    "\n",
    "# Compile complete results\n",
    "complete_results = {\n",
    "    'initial_bias_state': initial_bias_state,\n",
    "    'bias_trajectory': trainer.bias_trajectory,\n",
    "    'final_bias_state': final_bias_state,\n",
    "    'model': model,\n",
    "    'tokenizer': tokenizer,\n",
    "    'demographic_test_sets': demographic_test_sets,\n",
    "    'seat_examples': seat_examples\n",
    "}\n",
    "\n",
    "# Save results\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save bias trajectory (without model objects)\n",
    "trajectory_for_save = {\n",
    "    'initial_bias_state': {k: v for k, v in initial_bias_state.items() \n",
    "                            if k not in ['seat_male_scores', 'seat_female_scores']},\n",
    "    'bias_trajectory': {str(step): {\n",
    "        'step': int(data['step']),\n",
    "        'epoch': float(data['epoch']),\n",
    "        'seat_effect_size': float(data['bias_state']['seat_effect_size']),\n",
    "        'performance_gaps': data['bias_state']['performance_gaps'],\n",
    "        'timestamp': data['timestamp']\n",
    "    } for step, data in trainer.bias_trajectory.items()},\n",
    "    'final_bias_state': {k: v for k, v in final_bias_state.items() \n",
    "                        if k not in ['seat_male_scores', 'seat_female_scores']}\n",
    "}\n",
    "\n",
    "with open(f\"{output_dir}/bias_trajectory.json\", 'w') as f:\n",
    "    json.dump(trajectory_for_save, f, indent=2)\n",
    "\n",
    "print(f\"✅ Results saved to {output_dir}/\")\n",
    "print(\"🎉 Bias propagation tracking complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c12135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bias propagation tracking analysis...\n",
      "🚀 STARTING COMPLETE BIAS PROPAGATION ANALYSIS\n",
      "======================================================================\n",
      "Model: bert-base-uncased\n",
      "Output Directory: ./bias_tracking_results\n",
      "======================================================================\n",
      "🚀 Starting Bias Propagation Tracking Analysis\n",
      "============================================================\n",
      "📋 Step 1: Loading data and models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 190317.10 examples/s]\n",
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 156772.77 examples/s]\n",
      "Filter: 100%|██████████| 10103/10103 [00:00<00:00, 134235.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic distribution in test set:\n",
      "  male: 517 examples\n",
      "  female: 156 examples\n",
      "  neutral: 9430 examples\n",
      "  all: 10103 examples\n",
      "\n",
      "Dataset split summary:\n",
      "  Original train: 67349 examples\n",
      "  New train: 57246 examples\n",
      "  New test: 10103 examples\n",
      "  Validation (for eval): 872 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 57246/57246 [00:27<00:00, 2105.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Step 2: Measuring initial bias state...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting bias propagation tracking analysis...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Option 1: Run full analysis\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m results, report \u001b[38;5;241m=\u001b[39m \u001b[43mrun_complete_bias_propagation_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./bias_tracking_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Option 2: Quick summary of existing results\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# print_quick_summary(\"./bias_tracking_results\")\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Option 3: Load and analyze saved results\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# saved_results = load_bias_tracking_results(\"./bias_tracking_results\")\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Analysis complete! Check the output directory for detailed results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mrun_complete_bias_propagation_analysis\u001b[1;34m(model_name, output_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Run bias tracking fine-tuning\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bias_tracking_fine_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Generate comprehensive analysis\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     report \u001b[38;5;241m=\u001b[39m generate_bias_propagation_report(results, output_dir)\n",
      "Cell \u001b[1;32mIn[10], line 113\u001b[0m, in \u001b[0;36mrun_bias_tracking_fine_tuning\u001b[1;34m(tokenizer_name, output_dir)\u001b[0m\n\u001b[0;32m    110\u001b[0m seat_examples \u001b[38;5;241m=\u001b[39m create_mini_seat_examples()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Step 2: Measuring initial bias state...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m initial_bias_state \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_current_bias_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseat_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemographic_test_sets\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Initial SEAT Effect Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_bias_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseat_effect_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_bias_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance_gaps\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[9], line 347\u001b[0m, in \u001b[0;36mmeasure_current_bias_state\u001b[1;34m(model, tokenizer, seat_examples, demographic_test_sets)\u001b[0m\n\u001b[0;32m    342\u001b[0m seat_effect_size, male_scores, female_scores \u001b[38;5;241m=\u001b[39m calculate_mini_seat_score(\n\u001b[0;32m    343\u001b[0m     seat_examples, model, tokenizer\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# Demographic performance evaluation\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m demographic_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_demographic_performance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemographic_test_sets\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# Calculate performance gaps\u001b[39;00m\n\u001b[0;32m    352\u001b[0m performance_gaps \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[9], line 313\u001b[0m, in \u001b[0;36mevaluate_demographic_performance\u001b[1;34m(model, tokenizer, demographic_test_sets)\u001b[0m\n\u001b[0;32m    310\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 313\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m    314\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m    315\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1483\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1483\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1495\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1497\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    994\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:651\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    648\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    649\u001b[0m past_key_value \u001b[38;5;241m=\u001b[39m past_key_values[i] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_layers.py:83\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:553\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    543\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:492\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    475\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    483\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    484\u001b[0m         hidden_states,\n\u001b[0;32m    485\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         output_attentions,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:434\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 434\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    436\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_complete_bias_propagation_analysis(model_name='bert-base-uncased', \n",
    "                                          output_dir=\"./bias_tracking_results\"):\n",
    "    \"\"\"\n",
    "    Run complete bias propagation tracking analysis\n",
    "    \n",
    "    This function executes the full pipeline:\n",
    "    1. Data preparation with demographic annotation\n",
    "    2. Bias tracking during fine-tuning\n",
    "    3. Evolution analysis and visualization\n",
    "    4. Comprehensive reporting\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 STARTING COMPLETE BIAS PROPAGATION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Output Directory: {output_dir}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Run bias tracking fine-tuning\n",
    "        results = run_bias_tracking_fine_tuning(\n",
    "            tokenizer_name=model_name,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        \n",
    "        # Generate comprehensive analysis\n",
    "        report = generate_bias_propagation_report(results, output_dir)\n",
    "        \n",
    "        print(\"\\n🎉 BIAS PROPAGATION ANALYSIS COMPLETE!\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"📁 Results saved to: {output_dir}/\")\n",
    "        print(f\"📊 Plots saved as: {output_dir}/bias_evolution_plots.png\")\n",
    "        print(f\"📋 Report saved as: {output_dir}/bias_propagation_report.json\")\n",
    "        print(f\"📈 Trajectory data: {output_dir}/bias_trajectory.json\")\n",
    "        \n",
    "        return results, report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during bias propagation analysis: {str(e)}\")\n",
    "        print(\"Please check your environment and try again.\")\n",
    "        raise e\n",
    "\n",
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_bias_tracking_results(results_dir=\"./bias_tracking_results\"):\n",
    "    \"\"\"Load saved bias tracking results for further analysis\"\"\"\n",
    "    \n",
    "    trajectory_file = f\"{results_dir}/bias_trajectory.json\"\n",
    "    report_file = f\"{results_dir}/bias_propagation_report.json\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if os.path.exists(trajectory_file):\n",
    "        with open(trajectory_file, 'r') as f:\n",
    "            results['trajectory'] = json.load(f)\n",
    "    \n",
    "    if os.path.exists(report_file):\n",
    "        with open(report_file, 'r') as f:\n",
    "            results['report'] = json.load(f)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_bias_trajectories(results_list, labels, output_dir=\"./bias_comparison\"):\n",
    "    \"\"\"Compare bias trajectories from multiple experiments\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for i, (results, label) in enumerate(zip(results_list, labels)):\n",
    "        if 'trajectory' in results and 'bias_trajectory' in results['trajectory']:\n",
    "            trajectory = results['trajectory']['bias_trajectory']\n",
    "            steps = [int(step) for step in trajectory.keys()]\n",
    "            seat_scores = [trajectory[str(step)]['seat_effect_size'] for step in steps]\n",
    "            \n",
    "            plt.plot(steps, seat_scores, 'o-', linewidth=2, label=label, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Training Step')\n",
    "    plt.ylabel('SEAT Effect Size')\n",
    "    plt.title('Bias Propagation Comparison Across Experiments')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/bias_trajectory_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def print_quick_summary(results_dir=\"./bias_tracking_results\"):\n",
    "    \"\"\"Print a quick summary of bias tracking results\"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = load_bias_tracking_results(results_dir)\n",
    "        \n",
    "        if 'report' in results:\n",
    "            report = results['report']\n",
    "            summary = report['experiment_summary']\n",
    "            analysis = report['propagation_analysis']\n",
    "            \n",
    "            print(\"\\n📋 QUICK BIAS PROPAGATION SUMMARY\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"Training Steps: {summary['total_training_steps']}\")\n",
    "            print(f\"Bias Measurements: {summary['bias_measurements_taken']}\")\n",
    "            print(f\"Initial SEAT Score: {summary['initial_seat_score']:.4f}\")\n",
    "            print(f\"Final SEAT Score: {summary['final_seat_score']:.4f}\")\n",
    "            print(f\"Bias Change: {analysis['bias_change']:.4f}\")\n",
    "            print(f\"Percent Change: {analysis['percent_change']:.1f}%\")\n",
    "            \n",
    "            print(f\"\\n💡 Recommendations:\")\n",
    "            for rec in report['recommendations']:\n",
    "                print(f\"   • {rec}\")\n",
    "        else:\n",
    "            print(\"❌ No bias tracking report found!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading results: {str(e)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run complete analysis\n",
    "    print(\"Starting bias propagation tracking analysis...\")\n",
    "    \n",
    "    # Option 1: Run full analysis\n",
    "    results, report = run_complete_bias_propagation_analysis(\n",
    "        model_name='bert-base-uncased',\n",
    "        output_dir=\"./bias_tracking_results\"\n",
    "    )\n",
    "    \n",
    "    # Option 2: Quick summary of existing results\n",
    "    # print_quick_summary(\"./bias_tracking_results\")\n",
    "    \n",
    "    # Option 3: Load and analyze saved results\n",
    "    # saved_results = load_bias_tracking_results(\"./bias_tracking_results\")\n",
    "    \n",
    "    print(\"\\n✅ Analysis complete! Check the output directory for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
