{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eca930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5059381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT_DIR = \"results_rq1\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "STATIC_EMBEDDING_NAMES = [\n",
    "    \"word2vec-google-news-300\",   \n",
    "    \"glove-wiki-gigaword-300\"     \n",
    "]\n",
    "\n",
    "\n",
    "BERT_MODEL = \"bert-base-uncased\"\n",
    "MAX_TEMPLATES = None           \n",
    "N_PERMUTATIONS = 10000          \n",
    "HOLM_ALPHA = 0.05\n",
    "BOOTSTRAP_N = 5000              \n",
    "BOOTSTRAP_SEAT_N = 2000         \n",
    "RUN_TEMPLATE_SENSITIVITY = True \n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "male_names = [\"John\", \"Paul\", \"Mike\", \"Kevin\", \"Steve\", \"Greg\", \"Jeff\", \"Bill\", \"Frank\", \"George\"]\n",
    "female_names = [\"Amy\", \"Joan\", \"Lisa\", \"Sarah\", \"Diana\", \"Kate\", \"Ann\", \"Donna\", \"Susan\", \"Carol\"]\n",
    "\n",
    "male_terms = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]\n",
    "female_terms = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
    "\n",
    "career_words = [\"executive\", \"management\", \"professional\", \"corporation\", \"salary\", \"office\", \"business\", \"career\"]\n",
    "family_words = [\"home\", \"parents\", \"children\", \"family\", \"cousins\", \"marriage\", \"wedding\", \"relatives\"]\n",
    "\n",
    "science_words = [\"science\", \"technology\", \"physics\", \"chemistry\", \"einstein\", \"nasa\", \"experiment\", \"astronomy\"]\n",
    "arts_words    = [\"poetry\", \"art\", \"shakespeare\", \"dance\", \"literature\", \"novel\", \"symphony\", \"drama\"]\n",
    "math_words    = [\"math\", \"algebra\", \"geometry\", \"calculus\", \"equations\", \"computation\", \"numbers\", \"theorem\"]\n",
    "\n",
    "WEAT_TESTS = {\n",
    "    \"WEAT6_gender_names__career_family\": {\n",
    "        \"X\": male_names,\n",
    "        \"Y\": female_names,\n",
    "        \"A\": career_words,\n",
    "        \"B\": family_words\n",
    "    },\n",
    "    \"WEAT7_science_arts__male_female_terms\": {\n",
    "        \"X\": science_words,\n",
    "        \"Y\": arts_words,\n",
    "        \"A\": male_terms,\n",
    "        \"B\": female_terms\n",
    "    },\n",
    "    \"WEAT8_math_arts__male_female_terms\": {\n",
    "        \"X\": math_words,\n",
    "        \"Y\": arts_words,\n",
    "        \"A\": male_terms,\n",
    "        \"B\": female_terms\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEAT_TEMPLATES = [\n",
    "    \"This is {}.\",\n",
    "    \"{} is a person.\",\n",
    "    \"They talked about {}.\",\n",
    "    \"I heard about {} yesterday.\",\n",
    "    \"People often mention {}.\",\n",
    "    \"The discussion was about {}.\",\n",
    "    \"One individual is named {}.\",\n",
    "    \"Here we consider {}.\",\n",
    "    \"Someone referred to {}.\",\n",
    "    \"Everyone knows {}.\"\n",
    "]\n",
    "if MAX_TEMPLATES is None:\n",
    "    MAX_TEMPLATES = len(SEAT_TEMPLATES)\n",
    "\n",
    "def cosine_sim(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v) + 1e-12)\n",
    "\n",
    "def weat_effect_size(X, Y, A, B, vecs):\n",
    "    def s(w):\n",
    "        return np.mean([cosine_sim(vecs[w], vecs[a]) for a in A]) - \\\n",
    "               np.mean([cosine_sim(vecs[w], vecs[b]) for b in B])\n",
    "    Xs = np.array([s(x) for x in X])\n",
    "    Ys = np.array([s(y) for y in Y])\n",
    "    pooled_std = np.std(np.concatenate([Xs, Ys]), ddof=1)\n",
    "    d = 0.0 if pooled_std == 0 else (Xs.mean() - Ys.mean()) / pooled_std\n",
    "    return float(d), Xs, Ys\n",
    "\n",
    "def permutation_test_weat(X, Y, A, B, vecs, n_perm=10000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    d_obs, Xs, Ys = weat_effect_size(X, Y, A, B, vecs)\n",
    "    concat = np.concatenate([Xs, Ys])\n",
    "    nX = len(Xs)\n",
    "    more_extreme = 0\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(concat)\n",
    "        Xp = concat[:nX]\n",
    "        Yp = concat[nX:]\n",
    "        pooled_std = np.std(concat, ddof=1)\n",
    "        d_perm = 0.0 if pooled_std == 0 else (Xp.mean() - Yp.mean()) / pooled_std\n",
    "        if abs(d_perm) >= abs(d_obs):\n",
    "            more_extreme += 1\n",
    "    p = (more_extreme + 1) / (n_perm + 1)\n",
    "    return float(d_obs), float(p)\n",
    "\n",
    "def holm_bonferroni(pvals_dict, alpha=0.05):\n",
    "    items = sorted(pvals_dict.items(), key=lambda x: x[1])\n",
    "    m = len(items)\n",
    "    out = {}\n",
    "    for i, (name, p) in enumerate(items, 1):\n",
    "        threshold = alpha / (m - i + 1)\n",
    "        reject = p <= threshold\n",
    "        out[name] = {\"p_raw\": p, \"p_holm\": min(1.0, p * (m - i + 1)), \"reject\": reject}\n",
    "    return {k: out[k] for k in pvals_dict.keys()}\n",
    "\n",
    "def bootstrap_corr(x, y, n_boot=5000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(x))\n",
    "    pears, spears = [], []\n",
    "    for _ in range(n_boot):\n",
    "        bs = rng.choice(idx, size=len(idx), replace=True)\n",
    "        pr, _ = pearsonr(x[bs], y[bs])\n",
    "        sr, _ = spearmanr(x[bs], y[bs])\n",
    "        pears.append(pr)\n",
    "        spears.append(sr)\n",
    "    return (\n",
    "        np.percentile(pears, [2.5, 97.5]).tolist(),\n",
    "        np.percentile(spears, [2.5, 97.5]).tolist()\n",
    "    )\n",
    "\n",
    "def bootstrap_seat_ci(X_scores, Y_scores, n_boot=2000, seed=42):\n",
    "    \"\"\"\n",
    "    Bootstrap CI for pooled SEAT d: resample indices over concatenated scores.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X_all = np.concatenate(X_scores)\n",
    "    Y_all = np.concatenate(Y_scores)\n",
    "    n_total = len(X_all) + len(Y_all)\n",
    "    all_scores = np.concatenate([X_all, Y_all])\n",
    "    labels = np.array([0]*len(X_all) + [1]*len(Y_all))  # 0->X, 1->Y\n",
    "    idx = np.arange(n_total)\n",
    "\n",
    "    def d_from_idx(idxs):\n",
    "        x_mask = labels[idxs] == 0\n",
    "        y_mask = ~x_mask\n",
    "        Xb = all_scores[idxs][x_mask]\n",
    "        Yb = all_scores[idxs][y_mask]\n",
    "        pooled_std = np.std(np.concatenate([Xb, Yb]), ddof=1)\n",
    "        return 0.0 if pooled_std == 0 else (Xb.mean() - Yb.mean()) / pooled_std\n",
    "\n",
    "    ds = []\n",
    "    for _ in range(n_boot):\n",
    "        bs_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "        ds.append(d_from_idx(bs_idx))\n",
    "    return np.percentile(ds, [2.5, 97.5]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_static_embeddings(names):\n",
    "    embeds = {}\n",
    "    for n in names:\n",
    "        try:\n",
    "            print(f\"↓ downloading/loading {n} ...\")\n",
    "            embeds[n] = api.load(n)  \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not load {n}: {e}\")\n",
    "    return embeds\n",
    "\n",
    "def run_weat_on_static_embeddings(weat_tests, embeddings, n_perm=N_PERMUTATIONS, out_dir=OUT_DIR):\n",
    "    if len(embeddings) == 0:\n",
    "        print(\"⚠️ No static embeddings. Skipping WEAT.\")\n",
    "        return None\n",
    "\n",
    "    all_rows, all_pvals = [], {}\n",
    "\n",
    "    for emb_name, kv in embeddings.items():\n",
    "        print(f\"\\n[WEAT] Using {emb_name}\")\n",
    "        def get_vec(w):\n",
    "            lw = w.lower()\n",
    "            if lw in kv:\n",
    "                return kv[lw]\n",
    "            if w in kv:\n",
    "                return kv[w]\n",
    "            return None\n",
    "\n",
    "        for test_name, test in weat_tests.items():\n",
    "            X = [w for w in test[\"X\"] if get_vec(w) is not None]\n",
    "            Y = [w for w in test[\"Y\"] if get_vec(w) is not None]\n",
    "            A = [w for w in test[\"A\"] if get_vec(w) is not None]\n",
    "            B = [w for w in test[\"B\"] if get_vec(w) is not None]\n",
    "\n",
    "            if not (len(X) and len(Y) and len(A) and len(B)):\n",
    "                print(f\"Skipping {test_name} for {emb_name}: missing words.\")\n",
    "                continue\n",
    "\n",
    "            words = set(X + Y + A + B)\n",
    "            vecs = {w: get_vec(w) for w in words}\n",
    "\n",
    "            d, p = permutation_test_weat(X, Y, A, B, vecs, n_perm=n_perm, seed=SEED)\n",
    "            all_rows.append({\n",
    "                \"embedding\": emb_name,\n",
    "                \"test\": test_name,\n",
    "                \"weat_d\": d,\n",
    "                \"p_value\": p,\n",
    "                \"n_perm\": n_perm,\n",
    "                \"n_X\": len(X), \"n_Y\": len(Y), \"n_A\": len(A), \"n_B\": len(B)\n",
    "            })\n",
    "            all_pvals[(emb_name, test_name)] = p\n",
    "\n",
    "    if not all_rows:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df.to_csv(os.path.join(out_dir, \"weat_results_raw.csv\"), index=False)\n",
    "\n",
    "    pvals_dict = {f\"{k[0]}::{k[1]}\": v for k, v in all_pvals.items()}\n",
    "    holm = holm_bonferroni(pvals_dict, alpha=HOLM_ALPHA)\n",
    "\n",
    "    holm_rows = []\n",
    "    for k, v in holm.items():\n",
    "        emb, test = k.split(\"::\")\n",
    "        holm_rows.append({\n",
    "            \"embedding\": emb,\n",
    "            \"test\": test,\n",
    "            \"p_raw\": v[\"p_raw\"],\n",
    "            \"p_holm\": v[\"p_holm\"],\n",
    "            f\"reject_at_alpha={HOLM_ALPHA}\": v[\"reject\"]\n",
    "        })\n",
    "    df_holm = pd.DataFrame(holm_rows)\n",
    "    df_merged = df.merge(df_holm, on=[\"embedding\", \"test\"])\n",
    "    df_merged.to_csv(os.path.join(out_dir, \"weat_results_holm.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n[WEAT] Summary:\")\n",
    "    print(df_merged)\n",
    "    return df_merged\n",
    "\n",
    "def bert_encode_templates(words, model, tokenizer, templates, max_templates, device=DEVICE):\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    with torch.no_grad():\n",
    "        for w in words:\n",
    "            reps = []\n",
    "            for template in templates[:max_templates]:\n",
    "                sent = template.format(w)\n",
    "                inp = tokenizer(sent, return_tensors=\"pt\").to(device)\n",
    "                outputs = model(**inp, output_hidden_states=True, return_dict=True)\n",
    "                hs = outputs.hidden_states[1:]  \n",
    "                cls = torch.stack([h[:, 0, :] for h in hs], dim=0).squeeze(1)  \n",
    "                reps.append(cls)\n",
    "            out[w] = torch.stack(reps, dim=0).mean(dim=0).cpu() \n",
    "    return out\n",
    "\n",
    "def seat_layerwise_effect_size(X, Y, A, B, reps_dict):\n",
    "    L = list(reps_dict.values())[0].shape[0]\n",
    "    d_per_layer = []\n",
    "    X_scores = [[] for _ in range(L)]\n",
    "    Y_scores = [[] for _ in range(L)]\n",
    "\n",
    "    A_means, B_means = [], []\n",
    "    for l in range(L):\n",
    "        A_stack = torch.stack([reps_dict[a][l] for a in A], dim=0)\n",
    "        B_stack = torch.stack([reps_dict[b][l] for b in B], dim=0)\n",
    "        A_means.append(A_stack.mean(dim=0))\n",
    "        B_means.append(B_stack.mean(dim=0))\n",
    "\n",
    "    for l in range(L):\n",
    "        def s(word):\n",
    "            v = reps_dict[word][l]\n",
    "            return torch.nn.functional.cosine_similarity(v, A_means[l], dim=0).item() - \\\n",
    "                   torch.nn.functional.cosine_similarity(v, B_means[l], dim=0).item()\n",
    "        Xs = np.array([s(x) for x in X])\n",
    "        Ys = np.array([s(y) for y in Y])\n",
    "        pooled_std = np.std(np.concatenate([Xs, Ys]), ddof=1)\n",
    "        d = 0.0 if pooled_std == 0 else (Xs.mean() - Ys.mean()) / pooled_std\n",
    "        d_per_layer.append(d)\n",
    "        X_scores[l] = Xs\n",
    "        Y_scores[l] = Ys\n",
    "\n",
    "    return np.array(d_per_layer), X_scores, Y_scores\n",
    "\n",
    "def permutation_test_seat_layerwise(X_scores, Y_scores, n_perm=10000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X_all = np.concatenate(X_scores)\n",
    "    Y_all = np.concatenate(Y_scores)\n",
    "    nX = len(X_all)\n",
    "    pooled_std = np.std(np.concatenate([X_all, Y_all]), ddof=1)\n",
    "    d_obs = (X_all.mean() - Y_all.mean()) / pooled_std if pooled_std > 0 else 0.0\n",
    "\n",
    "    concat = np.concatenate([X_all, Y_all])\n",
    "    more_extreme = 0\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(concat)\n",
    "        Xp = concat[:nX]\n",
    "        Yp = concat[nX:]\n",
    "        pooled_std_p = np.std(concat, ddof=1)\n",
    "        d_perm = (Xp.mean() - Yp.mean()) / pooled_std_p if pooled_std_p > 0 else 0.0\n",
    "        if abs(d_perm) >= abs(d_obs):\n",
    "            more_extreme += 1\n",
    "    p = (more_extreme + 1) / (n_perm + 1)\n",
    "    return float(d_obs), float(p)\n",
    "\n",
    "def run_seat_on_bert(weat_tests, model_name=BERT_MODEL, templates=SEAT_TEMPLATES,\n",
    "                     max_templates=MAX_TEMPLATES, n_perm=N_PERMUTATIONS, out_dir=OUT_DIR):\n",
    "    print(f\"\\n[SEAT] Loading {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "\n",
    "    rows, pvals = [], {}\n",
    "\n",
    "    for test_name, test in weat_tests.items():\n",
    "        X, Y, A, B = test[\"X\"], test[\"Y\"], test[\"A\"], test[\"B\"]\n",
    "        words = list(set(X + Y + A + B))\n",
    "        reps = bert_encode_templates(words, model, tokenizer, templates, max_templates, device=DEVICE)\n",
    "\n",
    "        d_layers, X_scores, Y_scores = seat_layerwise_effect_size(X, Y, A, B, reps)\n",
    "        d_mean = float(np.mean(d_layers))\n",
    "        d_max  = float(np.max(np.abs(d_layers)) * np.sign(d_layers[np.argmax(np.abs(d_layers))]))\n",
    "\n",
    "        d_pooled, p = permutation_test_seat_layerwise(X_scores, Y_scores, n_perm=n_perm, seed=SEED)\n",
    "        d_ci = bootstrap_seat_ci(X_scores, Y_scores, n_boot=BOOTSTRAP_SEAT_N, seed=SEED)\n",
    "\n",
    "        for l, d in enumerate(d_layers):\n",
    "            rows.append({\n",
    "                \"model\": model_name,\n",
    "                \"test\": test_name,\n",
    "                \"layer\": l + 1,\n",
    "                \"seat_d\": float(d),\n",
    "                \"seat_d_mean\": d_mean,\n",
    "                \"seat_d_max\": d_max,\n",
    "                \"seat_d_pooled\": d_pooled,\n",
    "                \"seat_d_pooled_ci_low\": d_ci[0],\n",
    "                \"seat_d_pooled_ci_high\": d_ci[1],\n",
    "                \"p_value\": p,\n",
    "                \"n_perm\": n_perm\n",
    "            })\n",
    "        pvals[(model_name, test_name)] = p\n",
    "\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        plt.plot(range(1, len(d_layers)+1), d_layers, marker='o')\n",
    "        plt.axhline(0, color='black', linewidth=1)\n",
    "        plt.title(f\"SEAT layer-wise effect size ({test_name})\")\n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(\"Cohen's d\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"seat_{test_name}_layerwise.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    if not rows:\n",
    "        return None, None\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(out_dir, \"seat_results_raw.csv\"), index=False)\n",
    "\n",
    "    pvals_dict = {f\"{k[0]}::{k[1]}\": v for k, v in pvals.items()}\n",
    "    holm = holm_bonferroni(pvals_dict, alpha=HOLM_ALPHA)\n",
    "\n",
    "    holm_rows = []\n",
    "    for k, v in holm.items():\n",
    "        mname, tname = k.split(\"::\")\n",
    "        holm_rows.append({\n",
    "            \"model\": mname,\n",
    "            \"test\": tname,\n",
    "            \"p_raw\": v[\"p_raw\"],\n",
    "            \"p_holm\": v[\"p_holm\"],\n",
    "            f\"reject_at_alpha={HOLM_ALPHA}\": v[\"reject\"]\n",
    "        })\n",
    "    df_holm = pd.DataFrame(holm_rows)\n",
    "    df_holm.to_csv(os.path.join(out_dir, \"seat_results_holm.csv\"), index=False)\n",
    "\n",
    "    seat_summary = (\n",
    "        df.groupby([\"model\", \"test\"])\n",
    "          .agg(seat_d_mean=(\"seat_d_mean\", \"first\"),\n",
    "               seat_d_pooled=(\"seat_d_pooled\", \"first\"),\n",
    "               seat_d_pooled_ci_low=(\"seat_d_pooled_ci_low\", \"first\"),\n",
    "               seat_d_pooled_ci_high=(\"seat_d_pooled_ci_high\", \"first\"),\n",
    "               p_value=(\"p_value\", \"first\"))\n",
    "          .reset_index()\n",
    "    )\n",
    "    seat_summary = seat_summary.merge(df_holm, on=[\"model\", \"test\"])\n",
    "    seat_summary.to_csv(os.path.join(out_dir, \"seat_results_summary.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n[SEAT] Summary:\")\n",
    "    print(seat_summary)\n",
    "    return df, seat_summary\n",
    "\n",
    "def run_seat_template_sensitivity(weat_tests, model_name=BERT_MODEL,\n",
    "                                  templates=SEAT_TEMPLATES, out_dir=OUT_DIR):\n",
    "    print(\"\\n[SEAT] Template sensitivity analysis\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "\n",
    "    rows = []\n",
    "    for test_name, test in weat_tests.items():\n",
    "        X, Y, A, B = test[\"X\"], test[\"Y\"], test[\"A\"], test[\"B\"]\n",
    "        words = list(set(X + Y + A + B))\n",
    "        for t in templates:\n",
    "            reps = bert_encode_templates(words, model, tokenizer, [t], 1, device=DEVICE)\n",
    "            d_layers, _, _ = seat_layerwise_effect_size(X, Y, A, B, reps)\n",
    "            rows.append({\n",
    "                \"model\": model_name,\n",
    "                \"test\": test_name,\n",
    "                \"template\": t,\n",
    "                \"seat_d_mean\": float(np.mean(d_layers)),\n",
    "                \"seat_d_max\": float(np.max(np.abs(d_layers)) * np.sign(d_layers[np.argmax(np.abs(d_layers))]))\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(out_dir, \"seat_template_sensitivity.csv\"), index=False)\n",
    "\n",
    "    for test_name in df[\"test\"].unique():\n",
    "        sub = df[df[\"test\"] == test_name]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(range(len(sub)), sub[\"seat_d_mean\"])\n",
    "        plt.axhline(0, color='black', linewidth=1)\n",
    "        plt.xticks(range(len(sub)), [f\"T{i+1}\" for i in range(len(sub))], rotation=45)\n",
    "        plt.ylabel(\"Mean SEAT d (across layers)\")\n",
    "        plt.title(f\"Template sensitivity: {test_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"seat_template_sensitivity_{test_name}.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Saved template sensitivity CSV/plots.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def correlate_weat_seat(weat_df, seat_summary_df, model_name=BERT_MODEL,\n",
    "                        out_dir=OUT_DIR, n_boot=BOOTSTRAP_N):\n",
    "    if weat_df is None or seat_summary_df is None:\n",
    "        print(\"⚠️ Missing WEAT or SEAT results; skipping correlation.\")\n",
    "        return None\n",
    "\n",
    "    d_weat = (weat_df.groupby(\"test\")[\"weat_d\"].mean()).rename(\"weat_d_mean\")\n",
    "    seat_use = (seat_summary_df[seat_summary_df[\"model\"] == model_name]\n",
    "                .set_index(\"test\")[\"seat_d_mean\"])\n",
    "\n",
    "    tests = sorted(set(d_weat.index) & set(seat_use.index))\n",
    "    if len(tests) < 2:\n",
    "        print(\"Not enough aligned tests to correlate.\")\n",
    "        return None\n",
    "\n",
    "    x = d_weat.loc[tests].values\n",
    "    y = seat_use.loc[tests].values\n",
    "\n",
    "    pear_r, pear_p = pearsonr(x, y)\n",
    "    spear_r, spear_p = spearmanr(x, y)\n",
    "\n",
    "    try:\n",
    "        pear_ci, spear_ci = bootstrap_corr(x, y, n_boot=n_boot, seed=SEED)\n",
    "    except Exception:\n",
    "        pear_ci, spear_ci = [np.nan, np.nan], [np.nan, np.nan]\n",
    "\n",
    "    res = {\n",
    "        \"tests_used\": tests,\n",
    "        \"pearson_r\": float(pear_r), \"pearson_p\": float(pear_p),\n",
    "        \"pearson_95ci\": pear_ci,\n",
    "        \"spearman_r\": float(spear_r), \"spearman_p\": float(spear_p),\n",
    "        \"spearman_95ci\": spear_ci,\n",
    "        \"n_tests\": len(tests)\n",
    "    }\n",
    "    with open(os.path.join(out_dir, \"weat_seat_correlation.json\"), \"w\") as f:\n",
    "        json.dump(res, f, indent=2)\n",
    "\n",
    "    print(\"\\n[WEAT vs SEAT] Correlation summary:\")\n",
    "    print(json.dumps(res, indent=2))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "↓ downloading/loading word2vec-google-news-300 ...\n",
      "↓ downloading/loading glove-wiki-gigaword-300 ...\n",
      "\n",
      "[WEAT] Using word2vec-google-news-300\n",
      "\n",
      "[WEAT] Using glove-wiki-gigaword-300\n",
      "\n",
      "[WEAT] Summary:\n",
      "                  embedding                                   test    weat_d  \\\n",
      "0  word2vec-google-news-300      WEAT6_gender_names__career_family  1.634555   \n",
      "1  word2vec-google-news-300  WEAT7_science_arts__male_female_terms  1.084427   \n",
      "2  word2vec-google-news-300     WEAT8_math_arts__male_female_terms  1.112460   \n",
      "3   glove-wiki-gigaword-300      WEAT6_gender_names__career_family  1.654423   \n",
      "4   glove-wiki-gigaword-300  WEAT7_science_arts__male_female_terms  1.368223   \n",
      "5   glove-wiki-gigaword-300     WEAT8_math_arts__male_female_terms  0.989790   \n",
      "\n",
      "    p_value  n_perm  n_X  n_Y  n_A  n_B     p_raw    p_holm  \\\n",
      "0  0.000200   10000   10   10    8    8  0.000200  0.001000   \n",
      "1  0.022798   10000    8    8    8    8  0.022798  0.045595   \n",
      "2  0.018998   10000    8    8    8    8  0.018998  0.056994   \n",
      "3  0.000100   10000   10   10    8    8  0.000100  0.000600   \n",
      "4  0.001200   10000    8    8    8    8  0.001200  0.004800   \n",
      "5  0.035996   10000    8    8    8    8  0.035996  0.035996   \n",
      "\n",
      "   reject_at_alpha=0.05  \n",
      "0                  True  \n",
      "1                  True  \n",
      "2                 False  \n",
      "3                  True  \n",
      "4                  True  \n",
      "5                  True  \n",
      "\n",
      "[SEAT] Loading bert-base-uncased\n",
      "\n",
      "[SEAT] Summary:\n",
      "               model                                   test  seat_d_mean  \\\n",
      "0  bert-base-uncased      WEAT6_gender_names__career_family     1.214395   \n",
      "1  bert-base-uncased  WEAT7_science_arts__male_female_terms     0.264816   \n",
      "2  bert-base-uncased     WEAT8_math_arts__male_female_terms     0.507525   \n",
      "\n",
      "   seat_d_pooled  seat_d_pooled_ci_low  seat_d_pooled_ci_high   p_value  \\\n",
      "0       0.445386              0.201694               0.669039  0.000200   \n",
      "1       0.345449              0.069374               0.607326  0.016498   \n",
      "2       0.297114              0.020943               0.565616  0.038396   \n",
      "\n",
      "      p_raw    p_holm  reject_at_alpha=0.05  \n",
      "0  0.000200  0.000600                  True  \n",
      "1  0.016498  0.032997                  True  \n",
      "2  0.038396  0.038396                  True  \n",
      "\n",
      "[SEAT] Template sensitivity analysis\n",
      "Saved template sensitivity CSV/plots.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_9280\\2768862624.py:151: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, _ = pearsonr(x[bs], y[bs])\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_9280\\2768862624.py:152: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, _ = spearmanr(x[bs], y[bs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WEAT vs SEAT] Correlation summary:\n",
      "{\n",
      "  \"tests_used\": [\n",
      "    \"WEAT6_gender_names__career_family\",\n",
      "    \"WEAT7_science_arts__male_female_terms\",\n",
      "    \"WEAT8_math_arts__male_female_terms\"\n",
      "  ],\n",
      "  \"pearson_r\": 0.8577121023235507,\n",
      "  \"pearson_p\": 0.3437704411122802,\n",
      "  \"pearson_95ci\": [\n",
      "    NaN,\n",
      "    NaN\n",
      "  ],\n",
      "  \"spearman_r\": 0.5,\n",
      "  \"spearman_p\": 0.6666666666666667,\n",
      "  \"spearman_95ci\": [\n",
      "    NaN,\n",
      "    NaN\n",
      "  ],\n",
      "  \"n_tests\": 3\n",
      "}\n",
      "\n",
      "✅ Done. Artifacts saved under: results_rq1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "\n",
    "    STATIC_EMBEDS = load_static_embeddings(STATIC_EMBEDDING_NAMES)\n",
    "\n",
    "\n",
    "    weat_df = run_weat_on_static_embeddings(\n",
    "        WEAT_TESTS,\n",
    "        STATIC_EMBEDS,\n",
    "        n_perm=N_PERMUTATIONS,\n",
    "        out_dir=OUT_DIR\n",
    "    )\n",
    "\n",
    "\n",
    "    seat_raw_df, seat_summary_df = run_seat_on_bert(\n",
    "        WEAT_TESTS,\n",
    "        model_name=BERT_MODEL,\n",
    "        templates=SEAT_TEMPLATES,\n",
    "        max_templates=MAX_TEMPLATES,\n",
    "        n_perm=N_PERMUTATIONS,\n",
    "        out_dir=OUT_DIR\n",
    "    )\n",
    "\n",
    "\n",
    "    if RUN_TEMPLATE_SENSITIVITY:\n",
    "        run_seat_template_sensitivity(\n",
    "            WEAT_TESTS,\n",
    "            model_name=BERT_MODEL,\n",
    "            templates=SEAT_TEMPLATES,\n",
    "            out_dir=OUT_DIR\n",
    "        )\n",
    "\n",
    "\n",
    "    correlate_weat_seat(weat_df, seat_summary_df, model_name=BERT_MODEL, out_dir=OUT_DIR)\n",
    "\n",
    "    print(\"\\n✅ Done. Artifacts saved under:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
